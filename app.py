# app.py
import streamlit as st
import cv2
import numpy as np
import pandas as pd
from PIL import Image
from io import BytesIO
from datetime import datetime
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib.pagesizes import A4
from reportlab.lib.units import mm
import base64
try:
    import onnxruntime as ort  # æ·±åº¦åˆ†å‰²æ¨ç†
except Exception:
    ort = None

st.set_page_config("çŸ³çªŸå¯ºå£ç”»ç—…å®³AIè¯†åˆ«å·¥å…·ï¼ˆå‡çº§ç‰ˆï¼‰", layout="wide", page_icon="ğŸ›ï¸")

# Session init
if "proc" not in st.session_state:
    st.session_state["proc"] = None

# ---------------------------
# Helpers: render inpainting UI
# ---------------------------
def render_inpainting_ui(img_rgb, mask_crack, mask_peel, mask_disc, mask_stain, mask_salt, mask_bio, default_open=True, key_suffix=""):
    st.markdown("### ğŸ§© å›¾åƒå¤åŸï¼ˆè¯•éªŒæ€§ Inpaintingï¼‰")
    with st.expander("å±•å¼€/æ”¶èµ·", expanded=default_open):
        sel_classes = st.multiselect(
            "é€‰æ‹©éœ€è¦å¤åŸçš„ç—…å®³ç±»åˆ«ï¼ˆå°†åŸºäºå…¶æ©è†œè¿›è¡Œä¿®è¡¥ï¼‰",
            ["è£‚ç¼","å‰¥è½","è¤ªè‰²","æ±¡æ¸/éœ‰æ–‘","ç›èš€/é£åŒ–","ç”Ÿç‰©é™„ç€"],
            default=["è£‚ç¼","å‰¥è½","æ±¡æ¸/éœ‰æ–‘"], key=f"sel_classes_{key_suffix}"
        )
        method = st.selectbox("ä¿®è¡¥ç®—æ³•", ["Telea", "Navier-Stokes"], index=0, key=f"method_{key_suffix}")
        radius = st.slider("ä¿®è¡¥åŠå¾„ï¼ˆåƒç´ ï¼‰", min_value=1, max_value=25, value=7, key=f"radius_{key_suffix}")
        go_restore = st.button("ç”Ÿæˆå¤åŸå›¾åƒ", key=f"restore_btn_{key_suffix}")
        if go_restore:
            class_to_mask = {
                "è£‚ç¼": mask_crack,
                "å‰¥è½": mask_peel,
                "è¤ªè‰²": mask_disc,
                "æ±¡æ¸/éœ‰æ–‘": mask_stain,
                "ç›èš€/é£åŒ–": mask_salt,
                "ç”Ÿç‰©é™„ç€": mask_bio,
            }
            union = np.zeros(mask_crack.shape, dtype=np.uint8)
            for c in sel_classes:
                m = class_to_mask.get(c)
                if m is not None:
                    union = cv2.bitwise_or(union, (m>0).astype(np.uint8)*255)
            num_labels, labels, stats, _ = cv2.connectedComponentsWithStats((union>0).astype(np.uint8), connectivity=8)
            filtered = np.zeros_like(union)
            for i in range(1, num_labels):
                area = int(stats[i, cv2.CC_STAT_AREA])
                if area >= 50:
                    filtered[labels==i] = 255
            flag = cv2.INPAINT_TELEA if method == "Telea" else cv2.INPAINT_NS
            src_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
            restored_bgr = cv2.inpaint(src_bgr, (filtered>0).astype(np.uint8), radius, flag)
            restored_rgb = cv2.cvtColor(restored_bgr, cv2.COLOR_BGR2RGB)
            st.image(restored_rgb, caption="å¤åŸç»“æœï¼ˆåŸºäºæ‰€é€‰æ©è†œï¼‰", width='stretch')
            _buf = BytesIO(); Image.fromarray(restored_rgb).save(_buf, format="PNG"); _buf.seek(0)
            st.download_button("ä¸‹è½½å¤åŸå›¾ï¼ˆPNGï¼‰", data=_buf.getvalue(), file_name="restored.png", mime="image/png")

# ---------------------------
# Utility helpers
# ---------------------------
def pil_from_cv2(cv2_img):
    """BGR or RGB? we expect RGB input"""
    if len(cv2_img.shape) == 3:
        return Image.fromarray(cv2_img)
    else:
        return Image.fromarray(cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB))

def encode_image_to_bytes(img_rgb):
    """PIL Image -> bytes"""
    buf = BytesIO()
    img_rgb.save(buf, format="PNG")
    buf.seek(0)
    return buf

def save_annotated_image_bytes(annotated_rgb):
    """Return bytesIO for embedding to reportlab or streamlit download"""
    pil = Image.fromarray(annotated_rgb)
    buf = BytesIO()
    pil.save(buf, format="PNG")
    buf.seek(0)
    return buf

# ---------------------------
# Material-specific parameters
# ---------------------------
MATERIAL_OPTIONS = [
    "æœªæŒ‡å®š",
    "å¤§è¶³çŸ³åˆ»ï¼ˆç ‚å²©ï¼‰",
    "äº‘å†ˆçŸ³çªŸï¼ˆç ‚å²©å¤¹æ³¥å²©ï¼‰",
    "æ•¦ç…Œè«é«˜çªŸï¼ˆç°æ³¥/é¢œæ–™å±‚ï¼‰",
    "æœ¨è´¨åŸºåº•ï¼ˆæœ¨æ¿ï¼‰"
]

MATERIAL_WEIGHTS = {
    # weights for severity scoring per category
    # categories: crack, peel, disc, stain, salt, bio
    "æœªæŒ‡å®š": {
        "crack": 1.0, "peel": 1.0, "disc": 1.0, "stain": 0.9, "salt": 1.0, "bio": 0.8
    },
    "å¤§è¶³çŸ³åˆ»ï¼ˆç ‚å²©ï¼‰": {
        "crack": 1.2, "peel": 1.3, "disc": 0.9, "stain": 0.9, "salt": 1.4, "bio": 0.8
    },
    "äº‘å†ˆçŸ³çªŸï¼ˆç ‚å²©å¤¹æ³¥å²©ï¼‰": {
        "crack": 1.3, "peel": 1.2, "disc": 1.0, "stain": 0.9, "salt": 1.3, "bio": 0.8
    },
    "æ•¦ç…Œè«é«˜çªŸï¼ˆç°æ³¥/é¢œæ–™å±‚ï¼‰": {
        "crack": 1.0, "peel": 1.1, "disc": 1.4, "stain": 1.1, "salt": 0.9, "bio": 0.8
    },
    "æœ¨è´¨åŸºåº•ï¼ˆæœ¨æ¿ï¼‰": {
        "crack": 1.1, "peel": 1.2, "disc": 1.0, "stain": 1.2, "salt": 0.6, "bio": 1.3
    }
}

MATERIAL_SUGGESTIONS = {
    "å¤§è¶³çŸ³åˆ»ï¼ˆç ‚å²©ï¼‰": [
        "ç ‚å²©è´¨åœ°ç–æ¾ï¼Œä¼˜å…ˆé˜²æ°´åŠ å›ºã€é˜²æ­¢ç›æä¸å´©è§£ã€‚",
        "é’ˆå¯¹å¤§é¢ç§¯å‰¥è½ï¼Œå»ºè®®è¿›è¡Œç‰©ç†åŠ å›ºä¸æ³¨æµ†ã€‚"
    ],
    "äº‘å†ˆçŸ³çªŸï¼ˆç ‚å²©å¤¹æ³¥å²©ï¼‰": [
        "æ§åˆ¶æ´çªŸæ¹¿åº¦ï¼Œæ£€æŸ¥å¤¹å±‚æ°´æ¸—ã€é‡‡å–æ³¨æµ†æˆ–æ”¯æ’‘åŠ å›ºã€‚",
        "æ³¨æ„è£‚ç¼æ³¨å…¥å’Œè£‚ç¼æ‰©å±•çš„ç›‘æµ‹ã€‚"
    ],
    "æ•¦ç…Œè«é«˜çªŸï¼ˆç°æ³¥/é¢œæ–™å±‚ï¼‰": [
        "é‡ç‚¹ä¿æŠ¤é¢œæ–™å±‚ï¼Œé¿å…ç›´æ¥è§¦æ‘¸ä¸æ¹¿çƒ­ç¯å¢ƒå˜åŠ¨ã€‚",
        "å¯¹äºèµ·ç”²ä¸é¢œæ–™è„±è½ï¼Œåº”é‡‡ç”¨å¯é€†æ€§ä¿®å¤ææ–™ä¼˜å…ˆã€‚"
    ],
    "æœ¨è´¨åŸºåº•ï¼ˆæœ¨æ¿ï¼‰": [
        "å…³æ³¨è™«è›€ã€éœ‰èŒä¸å«æ°´ç‡å˜åŒ–ï¼Œå¿…è¦æ—¶è¿›è¡Œé˜²è™«ä¸é™¤æ¹¿å¤„ç†ã€‚",
        "é¿å…å¼ºå…‰ç›´å°„ä¸å¤§å¹…æ¸©æ¹¿å˜åŒ–ï¼Œè¡¨å±‚å»ºè®®ä½¿ç”¨å¯é€†æ€§ä¿æŠ¤æ¶‚å±‚ã€‚"
    ]
}

# ç»†åŒ–ï¼šæŒ‰ç—…å®³ç±»å‹å’Œæ¯”ä¾‹ç”Ÿæˆå»ºè®®
def build_recommendations(material, pct_map, overall_severity):
    recs = []
    m = material
    cp = pct_map.get('crack', 0.0)
    pp = pct_map.get('peel', 0.0)
    dp = pct_map.get('disc', 0.0)
    sp = pct_map.get('stain', 0.0)
    sap = pct_map.get('salt', 0.0)
    bp = pct_map.get('bio', 0.0)

    # è£‚ç¼
    if cp > 0.1:
        if cp < 1:
            recs.append("è£‚ç¼è½»åº¦ï¼šå»ºè®®è£‚ç¼ç›‘æµ‹ä¸è®°å½•ï¼Œé¿å…éœ‡åŠ¨ä¸å¹²æ¹¿å˜åŠ¨ï¼›å¿…è¦æ—¶è¡¨é¢åŠ å›ºã€‚")
        elif cp < 5:
            recs.append("è£‚ç¼ä¸­åº¦ï¼šè¿›è¡Œè£‚ç¼èµ°å‘/å®½åº¦æµ‹é‡ä¸å®šæœŸå¤æµ‹ï¼›å¯é‡‡ç”¨å¾®æ³¨æµ†æˆ–ä½é»åº¦åŠ å›ºæ ‘è„‚ï¼ˆå¯é€†/ä½æŒ¥å‘ï¼‰è¿›è¡Œå¡«å……ä¸åŠ å›ºã€‚")
        else:
            recs.append("è£‚ç¼é‡åº¦ï¼šä¼˜å…ˆå®æ–½ç»“æ„åŠ å›ºï¼ˆæ”¯æ’‘/é”šå›º/æ³¨æµ†ï¼‰ï¼Œå¹¶æŸ¥æ˜è‡´å› ï¼ˆæ¸—æ°´ã€æ¸©å˜ã€åº”åŠ›ï¼‰ï¼ŒåŒæ­¥å¼€å±•é•¿æœŸç›‘æµ‹ã€‚")
        if "æœ¨è´¨" in m:
            recs.append("æœ¨è´¨æ³¨æ„ï¼šä¼˜å…ˆæ§åˆ¶å«æ°´ç‡ä¸æ¸©æ¹¿ç¨³å®šï¼Œè£‚ç¼éƒ¨ä½é¿å…çƒ­èƒ€å†·ç¼©åå¤ï¼›åŠ å›ºææ–™éœ€å…¼å®¹æœ¨æçº¤ç»´ã€‚")

    # å‰¥è½/èµ·ç”²
    if pp > 0.1:
        if pp < 1:
            recs.append("å‰¥è½è½»åº¦ï¼šå°é¢ç§¯èµ·ç”²å¯å…ˆåšè¾¹ç¼˜ç‚¹å›ºä¸å±€éƒ¨å›è´´ï¼Œç°åœºè§‚å¯Ÿå…¶å‘å±•è¶‹åŠ¿ã€‚")
        elif pp < 5:
            recs.append("å‰¥è½ä¸­åº¦ï¼šå¯¹ç©ºé¼“/èµ·ç”²åŒºåŸŸè¿›è¡Œæ³¨æµ†å›è´´ï¼Œè¾¹ç•Œå¤„é‡‡ç”¨é€æ®µåŠ å›ºï¼›ä½œä¸šå‰è¿›è¡Œææ€§ä¸ç²˜ç»“è¯•éªŒã€‚")
        else:
            recs.append("å‰¥è½é‡åº¦ï¼šå¤§é¢ç§¯é¢å±‚ä¸ç¨³ï¼Œéœ€åˆ†åŒºåˆ†æ­¥å›è´´ä¸ç½‘æ ¼åŒ–ç®¡ç†ï¼Œè¿‡ç¨‹ä¸­ä¿æŒç¯å¢ƒç¨³å®šå¹¶åšå¥½æ”¯æ’‘ä¸é˜²å è½é˜²æŠ¤ã€‚")
        if "ç ‚å²©" in m:
            recs.append("ç ‚å²©æ³¨æ„ï¼šå…ˆåšåŸºä½“å«ç›/å«æ°´è¯„ä¼°ï¼Œå¿…è¦æ—¶å…ˆæœŸè„±ç›ä¸å¹²ç‡¥åå†è¡Œå›è´´åŠ å›ºã€‚")

    # è¤ªè‰²/ç²‰åŒ–
    if dp > 0.1:
        if dp < 1:
            recs.append("è¤ªè‰²è½»åº¦ï¼šåŠ å¼ºå…‰ç…§ä¸æ¸©æ¹¿ç®¡ç†ï¼Œé¿å…è§¦æ‘¸ä¸é£æ²™ç£¨èš€ï¼›å»ºç«‹é«˜ä¿çœŸå½±åƒæ¡£æ¡ˆã€‚")
        elif dp < 5:
            recs.append("è¤ªè‰²ä¸­åº¦ï¼šè¿›è¡Œé¢œæ–™å±‚ç¨³å›ºæ€§æµ‹è¯•ï¼Œé€‰æ‹©ä½å…‰æ³½ã€å¯é€†çš„è¡¨é¢ç¨³è‰²/å›ºè‰²å¤„ç†ï¼›é™å®šå‚è§‚è·ç¦»ä¸æ—¶é—´ã€‚")
        else:
            recs.append("è¤ªè‰²é‡åº¦ï¼šç»„ç»‡ææ–™å­¦è¯„ä¼°ï¼ˆé¢œæ–™çŸ¿ç‰©ä¸é»ç»“ç›¸ï¼‰ï¼Œé‡‡ç”¨æœ€å°å¹²é¢„çš„å¯é€†ç¨³è‰²ä½“ç³»å¹¶å»ºç«‹é•¿æœŸå…‰ç…§é˜ˆå€¼ç®¡ç†ã€‚")
        if "ç°æ³¥/é¢œæ–™" in m:
            recs.append("ç°æ³¥/é¢œæ–™å±‚æ³¨æ„ï¼šä¸¥æ§ç´«å¤–ä¸æŒ¥å‘æ€§æ±¡æŸ“ç‰©ï¼Œæ“ä½œä½¿ç”¨ä¸­æ€§pHæ¸…æ´ä¸ä¿æŠ¤ä½“ç³»ï¼Œé¿å…æ·±åº¦æ¸—å…¥å‹ææ–™ã€‚")

    # æ±¡æ¸/éœ‰æ–‘
    if sp > 0.1:
        if sp < 1:
            recs.append("æ±¡æ¸è½»åº¦ï¼šé‡‡ç”¨å¹²å¼/ä½æ¹¿æ¸…æ´ï¼ˆè½¯åˆ·/å¾®å¸ï¼‰å»é™¤è¡¨é¢å°˜å¢ï¼Œå…ˆåšå°æ ·è¯•éªŒã€‚")
        elif sp < 5:
            recs.append("æ±¡æ¸ä¸­åº¦ï¼šå±€éƒ¨é…åˆå‡èƒ¶æ¸…æ´ä¸æ§æ¹¿å¤„ç†ï¼Œæ¸…æ´ååšå†æ±¡æŸ“é˜²æŠ¤ã€‚")
        else:
            recs.append("æ±¡æ¸é‡åº¦ï¼šåˆ¶å®šåˆ†åŒºæ¸…æ´æ–¹æ¡ˆï¼Œé…åˆç¯å¢ƒæ²»ç†ï¼ˆè¿‡æ»¤/å¯†å°/äººæµæ§åˆ¶ï¼‰å¹¶è¯„ä¼°é¢œæ–™å±‚ç¨³å®šæ€§ã€‚")

    # ç›èš€/é£åŒ–
    if sap > 0.1:
        if sap < 1:
            recs.append("ç›èš€è½»åº¦ï¼šç›‘æµ‹ç›èŠ±ä¸ç™½åŒ–ï¼Œæ§åˆ¶æ°´æºä¸æ¹¿åº¦æ³¢åŠ¨ï¼›é¿å…ç›´æ¥æ°´æ´—é€ æˆç›è¿ç§»ã€‚")
        elif sap < 5:
            recs.append("ç›èš€ä¸­åº¦ï¼šå®æ–½æ¸©å’Œè„±ç›ï¼ˆçº¸æµ†/å‡èƒ¶ï¼‰ä¸æ°”å€™è°ƒæ§ï¼Œéšåè¿›è¡ŒåŸºä½“åŠ å›ºï¼›å¿…è¦æ—¶è¡¨é¢é˜²ç›å±éšœã€‚")
        else:
            recs.append("ç›èš€é‡åº¦ï¼šå…ˆæœŸç³»ç»Ÿè„±ç›ä¸å¹²ç‡¥ï¼Œå†åˆ†é˜¶æ®µç»“æ„ä¸è¡¨å±‚åŠ å›ºï¼›å»ºç«‹é•¿æœŸæ¸—æ°´/å«ç›ç›‘æµ‹ä½“ç³»ã€‚")
        if "æœ¨è´¨" in m:
            recs.append("æœ¨è´¨æ³¨æ„ï¼šç›èš€é€šå¸¸æ¬¡è¦ï¼Œé‡ç‚¹æ”¾åœ¨é˜²éœ‰ä¸å«æ°´ç‡æ§åˆ¶ï¼Œä¸å®œé‡‡ç”¨é«˜å«æ°´å¤„ç†ã€‚")

    # ç”Ÿç‰©é™„ç€
    if bp > 0.1:
        if bp < 1:
            recs.append("ç”Ÿç‰©è½»åº¦ï¼šå¢å¼ºé€šé£ä¸å¹²ç‡¥ï¼Œæ¶ˆé™¤ç§¯å°˜ä¸è¥å…»æºï¼Œç‰©ç†æ€§å»é™¤ä¸ºä¸»ã€‚")
        elif bp < 5:
            recs.append("ç”Ÿç‰©ä¸­åº¦ï¼šå°èŒƒå›´ä½¿ç”¨ä½æ¯’å¯é€†æ€§ç”Ÿç‰©æŠ‘åˆ¶å‰‚ï¼ˆå…ˆè¯•éªŒå†ä½¿ç”¨ï¼‰ï¼Œå¹¶æŒç»­æ§æ¹¿æ§å…‰ã€‚")
        else:
            recs.append("ç”Ÿç‰©é‡åº¦ï¼šåˆ¶å®šç»¼åˆæ²»ç†ï¼ˆæ§æ¹¿ã€æ§å…‰ã€å®šæœŸç»´æŠ¤ä¸è¿‡æ»¤ï¼‰ï¼Œå¿…è¦æ—¶åˆ†æ‰¹æ¬¡åŒ–å­¦æŠ‘åˆ¶å¹¶è¯„ä¼°å¯¹é¢œæ–™å±‚å½±å“ã€‚")
        if "æœ¨è´¨" in m:
            recs.append("æœ¨è´¨æ³¨æ„ï¼šä¼˜å…ˆé˜²éœ‰é˜²è™«ï¼Œè€ƒè™‘ç†è’¸/å±€éƒ¨æŠ—èŒä¸é˜²è™«å¤„ç½®ï¼Œå¹¶ä¸¥æ§å«æ°´ç‡ã€‚")

    # æ€»ä½“ç­–ç•¥
    if overall_severity < 5:
        recs.append("æ€»ä½“ï¼šé—®é¢˜è½»å¾®ï¼Œçº³å…¥å¸¸è§„å·¡æ£€ä¸å½±åƒæ¡£æ¡ˆç®¡ç†ï¼ŒåŠå¹´/ä¸€å¹´å¤æŸ¥ã€‚")
    elif overall_severity < 20:
        recs.append("æ€»ä½“ï¼šä¸­åº¦ç—…å®³ï¼Œå»ºè®®åˆ¶å®šåˆ†åŒºæ²»ç†è®¡åˆ’ä¸ä¼˜å…ˆçº§ï¼Œå…ˆåšæ ·åŒºè¯•éªŒåå†å…¨é¢å±•å¼€ã€‚")
    else:
        recs.append("æ€»ä½“ï¼šé‡åº¦ç—…å®³ï¼Œå°½å¿«ç»„ç»‡è·¨ä¸“ä¸šå›¢é˜Ÿï¼ˆç»“æ„ã€ææ–™ã€ç¯å¢ƒï¼‰è”åˆè¯„ä¼°ä¸å¤„ç½®ï¼Œè®¾ç½®é•¿æœŸç›‘æµ‹ã€‚")

    # é™„ï¼šæè´¨ä¸“ç”¨æç¤º
    recs += MATERIAL_SUGGESTIONS.get(m, [])
    return recs

# ---------------------------
# Image preprocessing & detection functions (classical CV baseline)
# ---------------------------

def preprocess_image(image_bgr, target_max_dim=1600):
    """Resize while keeping aspect ratio for reasonable processing time."""
    h, w = image_bgr.shape[:2]
    scale = 1.0
    max_dim = max(h, w)
    if max_dim > target_max_dim:
        scale = target_max_dim / max_dim
        image_bgr = cv2.resize(image_bgr, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)
    return image_bgr, scale

def detect_cracks(gray):
    """Detect fine elongated structures (baseline): morphological thinning + contour filtering."""
    # enhance contrast
    gray_eq = cv2.equalizeHist(gray)
    # use Scharr or Sobel to get strong gradients
    grad_x = cv2.Sobel(gray_eq, cv2.CV_16S, 1, 0, ksize=3)
    grad_y = cv2.Sobel(gray_eq, cv2.CV_16S, 0, 1, ksize=3)
    grad = cv2.convertScaleAbs(cv2.addWeighted(cv2.convertScaleAbs(grad_x), 0.5, cv2.convertScaleAbs(grad_y), 0.5, 0))
    # binary threshold + morphological closing to join thin lines
    _, th = cv2.threshold(grad, 30, 255, cv2.THRESH_BINARY)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=1)
    # find contours and filter elongated
    cnts = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = cnts[0] if len(cnts) == 2 else cnts[1]
    boxes = []
    mask = np.zeros_like(th)
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        area = w*h
        if area < 80: 
            continue
        # elongated or thin filter
        if (w > 4*h) or (h > 4*w) or (area < 200 and max(w,h) > 40):
            boxes.append((x,y,w,h))
            cv2.drawContours(mask, [c], -1, 255, -1)
    return boxes, mask

def detect_peeling(hsv):
    """Low saturation patches (å‰¥è½/ç°ç™½æ–‘å—)"""
    h,s,v = cv2.split(hsv)
    # threshold low saturation but not pure dark
    low_sat = cv2.inRange(hsv, (0,0,40), (180,70,255))
    # remove tiny speckles
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7))
    low_sat = cv2.morphologyEx(low_sat, cv2.MORPH_OPEN, kernel, iterations=1)
    cnts = cv2.findContours(low_sat, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = cnts[0] if len(cnts) == 2 else cnts[1]
    boxes = []
    mask = np.zeros_like(low_sat)
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        if w*h < 400: 
            continue
        boxes.append((x,y,w,h))
        cv2.drawContours(mask, [c], -1, 255, -1)
    return boxes, mask

def detect_discoloration(hsv):
    """Overly bright or faded regions: high V with low to mid saturation"""
    lower = np.array([0,0,180])
    upper = np.array([180,90,255])
    light_mask = cv2.inRange(hsv, lower, upper)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))
    light_mask = cv2.morphologyEx(light_mask, cv2.MORPH_OPEN, kernel, iterations=1)
    cnts = cv2.findContours(light_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = cnts[0] if len(cnts) == 2 else cnts[1]
    boxes = []
    mask = np.zeros_like(light_mask)
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        if w*h < 300: 
            continue
        boxes.append((x,y,w,h))
        cv2.drawContours(mask, [c], -1, 255, -1)
    return boxes, mask

# ---------------------------
# Material classification (heuristic + optional ONNX)
# ---------------------------
def classify_material_heuristic(image_bgr):
    """Return (material_name, confidence_0_1, details_dict) based on simple cues.
    Heuristic cues:
    - Brown/orange ratio (wood tendency)
    - Orientation coherence (wood grain)
    - High-bright low-sat salts (stone tendency)
    """
    img_small = cv2.resize(image_bgr, (min(640, image_bgr.shape[1]), min(640, image_bgr.shape[0])), interpolation=cv2.INTER_AREA)
    hsv = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)
    # brown-ish mask (wood): hue 10-30, moderate saturation/value
    brown = cv2.inRange(hsv, (10, 40, 40), (30, 255, 220))
    brown_ratio = float(np.mean(brown > 0))

    # salt-like (stone efflorescence): very bright low S
    salt_like = cv2.inRange(hsv, (0, 0, 220), (180, 40, 255))
    salt_ratio = float(np.mean(salt_like > 0))

    # orientation coherence via gradients
    gray = cv2.cvtColor(img_small, cv2.COLOR_BGR2GRAY)
    gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)
    gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)
    mag, ang = cv2.cartToPolar(gx, gy, angleInDegrees=True)
    # compute histogram concentration around main orientation
    ang_mask = mag > (np.percentile(mag, 75))
    main_orient = np.median(ang[ang_mask]) if np.any(ang_mask) else 0.0
    concentr = float(np.mean(np.abs(((ang - main_orient + 90) % 180) - 90) < 10))

    # crude decision
    wood_score = 0.55 * brown_ratio + 0.35 * concentr + 0.10 * (1.0 - salt_ratio)
    stone_score = 0.60 * (1.0 - brown_ratio) + 0.25 * (1.0 - concentr) + 0.15 * salt_ratio

    if wood_score > stone_score:
        name = "æœ¨è´¨åŸºåº•ï¼ˆæœ¨æ¿ï¼‰"
        conf = min(1.0, max(0.0, (wood_score - stone_score) * 2.0))
    else:
        # choose between known stone presets by default to "æœªæŒ‡å®š" or closest
        name = "å¤§è¶³çŸ³åˆ»ï¼ˆç ‚å²©ï¼‰"
        conf = min(1.0, max(0.0, (stone_score - wood_score) * 2.0))

    details = {
        'brown_ratio': round(brown_ratio, 4),
        'salt_ratio': round(salt_ratio, 4),
        'orientation_concentration': round(concentr, 4)
    }
    return name, conf, details

def run_material_model(image_bgr, model_path, providers=None, class_names=None):
    if ort is None:
        raise RuntimeError("æœªå®‰è£… onnxruntimeï¼Œè¯·å…ˆå®‰è£…ï¼špip install onnxruntime")
    session = ort.InferenceSession(model_path, providers=providers or ["CPUExecutionProvider"])
    # preprocess to square 224
    target = 224
    img = cv2.resize(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB), (target, target), interpolation=cv2.INTER_AREA)
    inp = img.astype(np.float32) / 255.0
    inp = np.transpose(inp, (2,0,1))[None, ...]
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name
    out = session.run([output_name], {input_name: inp})[0]
    # softmax
    if out.ndim == 2 and out.shape[0] == 1:
        logits = out[0]
    elif out.ndim == 1:
        logits = out
    else:
        raise ValueError("æè´¨æ¨¡å‹è¾“å‡ºå½¢çŠ¶ä¸æ”¯æŒï¼š" + str(out.shape))
    exps = np.exp(logits - np.max(logits))
    probs = exps / np.sum(exps)
    if class_names is None:
        class_names = [
            "æœªæŒ‡å®š",
            "å¤§è¶³çŸ³åˆ»ï¼ˆç ‚å²©ï¼‰",
            "äº‘å†ˆçŸ³çªŸï¼ˆç ‚å²©å¤¹æ³¥å²©ï¼‰",
            "æ•¦ç…Œè«é«˜çªŸï¼ˆç°æ³¥/é¢œæ–™å±‚ï¼‰",
            "æœ¨è´¨åŸºåº•ï¼ˆæœ¨æ¿ï¼‰"
        ]
    idx = int(np.argmax(probs))
    return class_names[idx], float(np.max(probs)), dict(zip(class_names[:len(probs)], [float(p) for p in probs]))

# é¢å¤–ç±»åˆ«ï¼ˆæ±¡æ¸/éœ‰æ–‘ã€ç›èš€/é£åŒ–ã€ç”Ÿç‰©é™„ç€ï¼‰
def detect_stain_mold(hsv):
    """Dark colored spots or stains: low V with moderate-high S"""
    lower = np.array([0, 40, 0])
    upper = np.array([180, 255, 90])
    mask = cv2.inRange(hsv, lower, upper)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = cnts[0] if len(cnts) == 2 else cnts[1]
    boxes = []
    mask_out = np.zeros_like(mask)
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        if w*h < 300:
            continue
        boxes.append((x,y,w,h))
        cv2.drawContours(mask_out, [c], -1, 255, -1)
    return boxes, mask_out

def detect_salt_weathering(hsv):
    """Efflorescence/whitish salt: very high V, very low S"""
    lower = np.array([0, 0, 200])
    upper = np.array([180, 35, 255])
    mask = cv2.inRange(hsv, lower, upper)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = cnts[0] if len(cnts) == 2 else cnts[1]
    boxes = []
    mask_out = np.zeros_like(mask)
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        if w*h < 400:
            continue
        boxes.append((x,y,w,h))
        cv2.drawContours(mask_out, [c], -1, 255, -1)
    return boxes, mask_out

def detect_bio_growth(hsv):
    """Biological growth (moss/algae): greenish hue, high S"""
    lower = np.array([35, 60, 40])
    upper = np.array([85, 255, 255])
    mask = cv2.inRange(hsv, lower, upper)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = cnts[0] if len(cnts) == 2 else cnts[1]
    boxes = []
    mask_out = np.zeros_like(mask)
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        if w*h < 300:
            continue
        boxes.append((x,y,w,h))
        cv2.drawContours(mask_out, [c], -1, 255, -1)
    return boxes, mask_out

# ---------------------------
# Deep model inference (ONNX)
# ---------------------------
def run_segmentation_model(image_bgr, model_path, input_size=512, class_ids=None, providers=None):
    """Run ONNX segmentation model and return masks dict.

    Assumptions:
    - Input: RGB float32 0-1, NCHW (1,C,H,W). We will transpose accordingly.
    - Output: either NCHW (1,C,H,W) or NHWC (1,H,W,C) or HW (single channel) or HxW (after squeeze).
    - Class mapping provided via class_ids: {'bg':0,'crack':1,'peel':2,'disc':3}.
    """
    if ort is None:
        raise RuntimeError("æœªå®‰è£… onnxruntimeï¼Œè¯·å…ˆå®‰è£…ï¼špip install onnxruntime")

    if class_ids is None:
        class_ids = {'bg': 0, 'crack': 1, 'peel': 2, 'disc': 3, 'stain': 4, 'salt': 5, 'bio': 6}

    # Prepare session
    session = ort.InferenceSession(model_path, providers=providers or ["CPUExecutionProvider"])

    # Preprocess: BGR->RGB, resize square, normalize to [0,1]
    h0, w0 = image_bgr.shape[:2]
    target = int(input_size)
    img_resized = cv2.resize(image_bgr, (target, target), interpolation=cv2.INTER_AREA)
    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
    inp = img_rgb.astype(np.float32) / 255.0
    # to NCHW
    inp = np.transpose(inp, (2,0,1))[None, ...]  # (1,3,H,W)

    # IO names
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name

    out = session.run([output_name], {input_name: inp})[0]
    # Postprocess to class map HxW
    class_map = None
    if out.ndim == 4:
        # (N,C,H,W) or (N,H,W,C)
        if out.shape[1] <= 6 and out.shape[0] == 1:  # likely NCHW classes small
            class_map = np.argmax(out[0], axis=0)
        elif out.shape[-1] <= 6 and out.shape[0] == 1:  # NHWC
            class_map = np.argmax(out[0], axis=-1)
        else:
            # fallback: take channel-argmax in the dimension that matches classes<=20
            if out.shape[1] < out.shape[-1]:
                class_map = np.argmax(out[0], axis=0)
            else:
                class_map = np.argmax(out[0], axis=-1)
    elif out.ndim == 3:
        # (C,H,W) or (H,W,C)
        if out.shape[0] <= 6:
            class_map = np.argmax(out, axis=0)
        elif out.shape[-1] <= 6:
            class_map = np.argmax(out, axis=-1)
        else:
            raise ValueError("æ— æ³•è§£ææ¨¡å‹è¾“å‡ºå½¢çŠ¶ï¼š" + str(out.shape))
    elif out.ndim == 2:
        # binary logits/mask -> treat >0.5 as class 'crack' by default
        class_map = (out > 0.5).astype(np.uint8) * class_ids.get('crack', 1)
    else:
        raise ValueError("æœªæ”¯æŒçš„æ¨¡å‹è¾“å‡ºç»´åº¦ï¼š" + str(out.shape))

    # Resize back to original size
    class_map = cv2.resize(class_map.astype(np.int32), (w0, h0), interpolation=cv2.INTER_NEAREST)

    crack_id = int(class_ids.get('crack', 1))
    peel_id = int(class_ids.get('peel', 2))
    disc_id = int(class_ids.get('disc', 3))
    stain_id = class_ids.get('stain', None)
    salt_id = class_ids.get('salt', None)
    bio_id = class_ids.get('bio', None)

    masks = {
        'crack': (class_map == crack_id).astype(np.uint8) * 255,
        'peel': (class_map == peel_id).astype(np.uint8) * 255,
        'disc': (class_map == disc_id).astype(np.uint8) * 255
    }
    if stain_id is not None:
        masks['stain'] = (class_map == int(stain_id)).astype(np.uint8) * 255
    if salt_id is not None:
        masks['salt'] = (class_map == int(salt_id)).astype(np.uint8) * 255
    if bio_id is not None:
        masks['bio'] = (class_map == int(bio_id)).astype(np.uint8) * 255
    return masks

# ---------------------------
# UI and main logic
# ---------------------------
st.markdown("<h1 style='text-align:center;color:#8B4513;'>ğŸ›ï¸ çŸ³çªŸå¯ºå£ç”»ç—…å®³AIè¯†åˆ«å·¥å…·ï¼ˆå‡çº§ç‰ˆï¼‰</h1>", unsafe_allow_html=True)
st.write("æœ¬å·¥å…·ä¸ºç§‘ç ”åŸå‹ï¼šé‡‡ç”¨ä¼ ç»Ÿå›¾åƒå¤„ç†æ–¹æ³•ä½œä¸ºåŸºçº¿ï¼Œå¹¶æä¾›æ·±åº¦æ¨¡å‹æ¥å…¥ç‚¹ï¼›è¾“å‡ºç—…å®³æ£€æµ‹ã€ä¸¥é‡åº¦è¯„åˆ†ã€æè´¨è‡ªé€‚åº”å»ºè®®ä¸å«æ ‡æ³¨å›¾åƒçš„ PDFã€‚")

# Sidebar controls
st.sidebar.markdown("### é…ç½®ä¸æè´¨é€‰æ‹©")
material = st.sidebar.selectbox("é€‰æ‹©å£ç”»æè´¨ï¼ˆå½±å“è¯„åˆ†ä¸å»ºè®®ï¼‰", MATERIAL_OPTIONS)
auto_material = st.sidebar.checkbox("è‡ªåŠ¨è¯†åˆ«æè´¨ï¼ˆè¯•éªŒæ€§ï¼‰", value=False)
mat_model_path = None
if auto_material:
    st.sidebar.markdown("- å¯é€‰ï¼šæä¾›æè´¨åˆ†ç±»ONNXæ¨¡å‹è·¯å¾„ï¼ˆè‹¥ç•™ç©ºåˆ™ä½¿ç”¨å¯å‘å¼è¯†åˆ«ï¼‰")
    mat_model_path = st.sidebar.text_input("æè´¨æ¨¡å‹è·¯å¾„ï¼ˆ.onnxï¼Œå¯é€‰ï¼‰", "")
use_deep = st.sidebar.checkbox("ä½¿ç”¨æ·±åº¦åˆ†å‰²æ¨¡å‹ï¼ˆONNXï¼‰", value=False)
model_path = None
model_input_size = 512
class_id_bg = 0
class_id_crack = 1
class_id_peel = 2
class_id_disc = 3
class_id_stain = 4
class_id_salt = 5
class_id_bio = 6
if use_deep:
    model_path = st.sidebar.text_input("æ¨¡å‹è·¯å¾„ï¼ˆ.onnxï¼‰", "")
    model_input_size = st.sidebar.selectbox("æ¨¡å‹è¾“å…¥å°ºå¯¸ï¼ˆæ–¹å½¢ï¼‰", [256, 320, 384, 512, 640, 768, 1024], index=3)
    st.sidebar.markdown("#### ç±»åˆ«IDæ˜ å°„ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰")
    col1, col2 = st.sidebar.columns(2)
    with col1:
        class_id_bg = st.number_input("èƒŒæ™¯ID", value=0, step=1)
        class_id_crack = st.number_input("è£‚ç¼ID", value=1, step=1)
        class_id_stain = st.number_input("æ±¡æ¸/éœ‰æ–‘ID", value=4, step=1)
    with col2:
        class_id_peel = st.number_input("å‰¥è½ID", value=2, step=1)
        class_id_disc = st.number_input("è¤ªè‰²ID", value=3, step=1)
        class_id_salt = st.number_input("ç›èš€/é£åŒ–ID", value=5, step=1)
    class_id_bio = st.sidebar.number_input("ç”Ÿç‰©é™„ç€ID", value=6, step=1)

# Display controls (å»æ‚åŒ–)
st.sidebar.markdown("### æ˜¾ç¤ºè®¾ç½®ï¼ˆå‡å°‘å¹²æ‰°ï¼‰")
display_mode = st.sidebar.selectbox(
    "æ˜¾ç¤ºæ–¹å¼",
    ["ä»…æ©è†œ", "ä»…è¾¹æ¡†", "è¾¹æ¡†+æ©è†œ"],
    index=0
)
min_area = st.sidebar.slider("æœ€å°ç›®æ ‡é¢ç§¯ï¼ˆåƒç´ ï¼‰", 0, 5000, 400, step=50)
show_crack = st.sidebar.checkbox("æ˜¾ç¤ºï¼šè£‚ç¼", True)
show_peel = st.sidebar.checkbox("æ˜¾ç¤ºï¼šå‰¥è½", True)
show_disc = st.sidebar.checkbox("æ˜¾ç¤ºï¼šè¤ªè‰²", True)
show_stain = st.sidebar.checkbox("æ˜¾ç¤ºï¼šæ±¡æ¸/éœ‰æ–‘", True)
show_salt = st.sidebar.checkbox("æ˜¾ç¤ºï¼šç›èš€/é£åŒ–", True)
show_bio = st.sidebar.checkbox("æ˜¾ç¤ºï¼šç”Ÿç‰©é™„ç€", True)
show_labels = st.sidebar.checkbox("åœ¨å›¾ä¸Šæ ‡æ³¨ç±»åˆ«ç®€å†™", True)
label_lang = st.sidebar.selectbox("æ ‡ç­¾æ ·å¼", ["ç®€å†™(EN)", "ä¸­æ–‡"], index=0)

# Upload (æ”¯æŒå†å²å¯¹æ¯”ï¼šå…è®¸ä¸Šä¼ æ—§å›¾åƒ)
st.markdown("#### 1) ä¸Šä¼ å›¾åƒï¼ˆå¯ä¸Šä¼  1-2 å¼ ç”¨äºæ—¶é—´å¯¹æ¯”ï¼‰")
uploaded = st.file_uploader("ä¸Šä¼ å½“å‰å›¾åƒï¼ˆå¿…å¡«ï¼‰", type=['jpg','jpeg','png'])
uploaded_prev = st.file_uploader("ä¸Šä¼ å†å²å›¾åƒï¼ˆå¯é€‰ï¼Œç”¨äºå¯¹æ¯”ï¼‰ï¼Œè‹¥æœ‰åˆ™ä¸ºåŒä¸€å£ç”»çš„æ—©æœŸç…§ç‰‡", type=['jpg','jpeg','png'])

analyze_btn = st.button("å¼€å§‹åˆ†æ")

if analyze_btn and uploaded is None:
    st.error("è¯·è‡³å°‘ä¸Šä¼ å½“å‰å›¾åƒä»¥è¿›è¡Œåˆ†æã€‚")

if uploaded is not None and analyze_btn:
    # read images
    file_bytes = np.asarray(bytearray(uploaded.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
    if img is None:
        st.error("æ— æ³•è¯»å–å›¾åƒï¼Œè¯·ç¡®è®¤æ ¼å¼æ­£ç¡®ã€‚")
    else:
        img_proc, scale = preprocess_image(img.copy())
        img_rgb = cv2.cvtColor(img_proc, cv2.COLOR_BGR2RGB)
        st.subheader("åŸå§‹å›¾åƒï¼ˆå·²ç¼©æ”¾ä»¥ä¾¿å¤„ç†ï¼‰")
        # Auto material detection
        detected_material = None
        detected_conf = None
        detected_details = None
        if auto_material:
            try:
                if mat_model_path:
                    detected_material, detected_conf, mat_probs = run_material_model(img_proc, mat_model_path)
                    detected_details = {"probs": mat_probs}
                else:
                    detected_material, detected_conf, detected_details = classify_material_heuristic(img_proc)
                st.info(f"è‡ªåŠ¨è¯†åˆ«æè´¨ï¼š{detected_material}ï¼ˆç½®ä¿¡åº¦ {detected_conf:.2f}ï¼‰")
                apply_mat = st.toggle("å°†è¯†åˆ«ç»“æœåº”ç”¨åˆ°è¯„åˆ†/å»ºè®®", value=True)
                if apply_mat:
                    material = detected_material
            except Exception as e:
                st.warning(f"è‡ªåŠ¨æè´¨è¯†åˆ«å¤±è´¥ï¼š{e}")

        st.image(img_rgb, width='stretch')

        # Optionally run deep model
        deep_masks = None
        if use_deep and model_path:
            try:
                deep_masks = run_segmentation_model(
                    img_proc,
                    model_path=model_path,
                    input_size=int(model_input_size),
                    class_ids={
                        'bg': int(class_id_bg),
                        'crack': int(class_id_crack),
                        'peel': int(class_id_peel),
                        'disc': int(class_id_disc),
                        'stain': int(class_id_stain),
                        'salt': int(class_id_salt),
                        'bio': int(class_id_bio)
                    },
                    providers=["CPUExecutionProvider"]
                )
                st.success("æ·±åº¦åˆ†å‰²å·²å¯ç”¨ï¼šç»“æœå°†æ›¿æ¢ä¼ ç»ŸCVæ©è†œã€‚")
            except Exception as e:
                st.error(f"æ·±åº¦æ¨¡å‹æ¨ç†å¤±è´¥ï¼š{e}")
                deep_masks = None

        # Baseline CV detections
        gray = cv2.cvtColor(img_proc, cv2.COLOR_BGR2GRAY)
        hsv = cv2.cvtColor(img_proc, cv2.COLOR_BGR2HSV)
        boxes_crack, mask_crack = detect_cracks(gray)
        boxes_peel, mask_peel = detect_peeling(hsv)
        boxes_disc, mask_disc = detect_discoloration(hsv)
        boxes_stain, mask_stain = detect_stain_mold(hsv)
        boxes_salt, mask_salt = detect_salt_weathering(hsv)
        boxes_bio, mask_bio = detect_bio_growth(hsv)

        # If deep_masks provided, prefer it
        if deep_masks:
            # expected keys 'crack','peel','disc' -> binary masks same size as img_proc
            if 'crack' in deep_masks:
                mask_crack = deep_masks['crack']
            if 'peel' in deep_masks:
                mask_peel = deep_masks['peel']
            if 'disc' in deep_masks:
                mask_disc = deep_masks['disc']
            if 'stain' in deep_masks:
                mask_stain = deep_masks['stain']
            if 'salt' in deep_masks:
                mask_salt = deep_masks['salt']
            if 'bio' in deep_masks:
                mask_bio = deep_masks['bio']

        # Annotate image for visualization
        annotated = img_rgb.copy()
        # Helper to draw boxes with filters
        def draw_boxes(boxes, color, visible, tag_text):
            if not visible or display_mode == "ä»…æ©è†œ":
                return
            for (x,y,w,h) in boxes:
                if w*h < min_area:
                    continue
                cv2.rectangle(annotated, (x,y), (x+w, y+h), color, 2)
                if show_labels:
                    # draw a small label background for readability
                    tx = x
                    ty = max(0, y-8)
                    text = tag_text
                    (tw, th), bl = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.45, 1)
                    cv2.rectangle(annotated, (tx, ty-th-4), (tx+tw+4, ty+2), (0,0,0), -1)
                    cv2.putText(annotated, text, (tx+2, ty-2), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 1, cv2.LINE_AA)

        # Draw per category (no Chinese labels on image toé¿å…é—®å·)
        # label text mapping
        if label_lang == "ä¸­æ–‡":
            # OpenCV ä¸æ”¯æŒä¸­æ–‡å­—ä½“ï¼Œå¯èƒ½æ˜¾ç¤ºé—®å·ï¼›è‹¥å‡ºç°ï¼Œè¯·åˆ‡æ¢åˆ°â€œç®€å†™(EN)â€
            crack_t, peel_t, disc_t, stain_t, salt_t, bio_t = "è£‚", "å‰¥", "è¤ª", "æ±¡", "ç›", "ç”Ÿ"
        else:
            crack_t, peel_t, disc_t, stain_t, salt_t, bio_t = "CR", "PL", "DC", "ST", "SA", "BIO"

        draw_boxes(boxes_crack, (255,0,0), show_crack, crack_t)
        draw_boxes(boxes_peel, (0,255,0), show_peel, peel_t)
        draw_boxes(boxes_disc, (0,0,255), show_disc, disc_t)
        draw_boxes(boxes_stain, (255,255,0), show_stain, stain_t)
        draw_boxes(boxes_salt, (0,255,255), show_salt, salt_t)
        draw_boxes(boxes_bio, (255,0,255), show_bio, bio_t)

        # Also overlay masks semi-transparently to show extent
        def overlay_mask(base_rgb, mask, color_rgb, alpha=0.35):
            overlay = base_rgb.copy()
            mask_bool = mask > 0
            overlay[mask_bool] = (overlay[mask_bool] * (1-alpha) + np.array(color_rgb) * alpha).astype(np.uint8)
            return overlay

        if display_mode in ("ä»…æ©è†œ", "è¾¹æ¡†+æ©è†œ"):
            if show_crack:
                annotated = overlay_mask(annotated, mask_crack, (255,0,0), alpha=0.25)
            if show_peel:
                annotated = overlay_mask(annotated, mask_peel, (0,255,0), alpha=0.18)
            if show_disc:
                annotated = overlay_mask(annotated, mask_disc, (0,0,255), alpha=0.18)
            if show_stain:
                annotated = overlay_mask(annotated, mask_stain, (255,255,0), alpha=0.20)
            if show_salt:
                annotated = overlay_mask(annotated, mask_salt, (0,255,255), alpha=0.18)
            if show_bio:
                annotated = overlay_mask(annotated, mask_bio, (255,0,255), alpha=0.20)

        st.subheader("åˆ†æç»“æœï¼ˆå¸¦æ ‡æ³¨ï¼‰")
        st.image(annotated, width='stretch')

        # Legend (å›¾ä¾‹) for colors
        legend_html = """
        <div style='display:flex;flex-wrap:wrap;gap:12px;margin:6px 0 10px 0;'>
          <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#ff0000;'></span><span>è£‚ç¼</span></div>
          <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#00cc00;'></span><span>å‰¥è½</span></div>
          <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#0000ff;'></span><span>è¤ªè‰²</span></div>
          <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#ffff00;'></span><span>æ±¡æ¸/éœ‰æ–‘</span></div>
          <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#00ffff;'></span><span>ç›èš€/é£åŒ–</span></div>
          <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#ff00ff;'></span><span>ç”Ÿç‰©é™„ç€</span></div>
        </div>
        """
        st.markdown(legend_html, unsafe_allow_html=True)

        # ---------------------
        # Quantification & scoring
        # ---------------------
        h,w = gray.shape
        total_pixels = h*w
        crack_area = int(np.sum(mask_crack>0))
        peel_area = int(np.sum(mask_peel>0))
        disc_area = int(np.sum(mask_disc>0))
        stain_area = int(np.sum(mask_stain>0))
        salt_area = int(np.sum(mask_salt>0))
        bio_area = int(np.sum(mask_bio>0))

        crack_pct = crack_area / total_pixels * 100
        peel_pct = peel_area / total_pixels * 100
        disc_pct = disc_area / total_pixels * 100
        stain_pct = stain_area / total_pixels * 100
        salt_pct = salt_area / total_pixels * 100
        bio_pct = bio_area / total_pixels * 100

        # severity score: weighted sum (0-100)
        weights = MATERIAL_WEIGHTS.get(material, MATERIAL_WEIGHTS["æœªæŒ‡å®š"])
        # normalize each by an empirical factor per category
        score = (
            weights.get('crack',1.0) * crack_pct * 1.8 +
            weights.get('peel',1.0) * peel_pct * 1.2 +
            weights.get('disc',1.0) * disc_pct * 1.5 +
            weights.get('stain',1.0) * stain_pct * 0.9 +
            weights.get('salt',1.0) * salt_pct * 1.6 +
            weights.get('bio',1.0) * bio_pct * 1.1
        )
        # map to 0-100
        severity = min(round(score,1), 100.0)

        st.markdown("### ğŸ“‹ é‡åŒ–ç»“æœ")
        st.write(f"- è£‚ç¼è¦†ç›–é¢ç§¯ï¼š{crack_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {crack_pct:.3f}%")
        st.write(f"- å‰¥è½è¦†ç›–é¢ç§¯ï¼š{peel_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {peel_pct:.3f}%")
        st.write(f"- è¤ªè‰²è¦†ç›–é¢ç§¯ï¼š{disc_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {disc_pct:.3f}%")
        st.write(f"- æ±¡æ¸/éœ‰æ–‘è¦†ç›–é¢ç§¯ï¼š{stain_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {stain_pct:.3f}%")
        st.write(f"- ç›èš€/é£åŒ–è¦†ç›–é¢ç§¯ï¼š{salt_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {salt_pct:.3f}%")
        st.write(f"- ç”Ÿç‰©é™„ç€è¦†ç›–é¢ç§¯ï¼š{bio_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {bio_pct:.3f}%")
        st.write(f"- æè´¨ï¼š**{material}**ï¼ˆç”¨äºè°ƒæ•´è¯„åˆ†ä¸å»ºè®®ï¼‰")
        st.metric("æ•´ä½“ç—…å®³ä¸¥é‡åº¦ï¼ˆ0-100ï¼‰", f"{severity}")

        # severity label
        if severity < 5:
            lvl = "è½»å¾®"
        elif severity < 20:
            lvl = "ä¸­ç­‰"
        else:
            lvl = "ä¸¥é‡"
        st.write(f"åˆ¤æ–­ç­‰çº§ï¼š**{lvl}**")

        # ---------------------
        # ç»†åŒ–ç—…ç†æŒ‡æ ‡ï¼ˆè¿é€šåŸŸ/å½¢æ€/æ–¹å‘ï¼‰
        # ---------------------
        def extract_components(mask, min_area_px=min_area):
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats((mask>0).astype(np.uint8), connectivity=8)
            rows = []
            for i in range(1, num_labels):
                area = int(stats[i, cv2.CC_STAT_AREA])
                if area < min_area_px:
                    continue
                x = int(stats[i, cv2.CC_STAT_LEFT])
                y = int(stats[i, cv2.CC_STAT_TOP])
                w_ = int(stats[i, cv2.CC_STAT_WIDTH])
                h_ = int(stats[i, cv2.CC_STAT_HEIGHT])
                elong = (max(w_, h_) / max(1.0, min(w_, h_)))
                ys, xs = np.where(labels == i)
                if xs.size > 5:
                    x_mean = xs.mean(); y_mean = ys.mean()
                    x_c = xs - x_mean; y_c = ys - y_mean
                    cov_xx = float(np.mean(x_c*x_c)); cov_yy = float(np.mean(y_c*y_c)); cov_xy = float(np.mean(x_c*y_c))
                    theta = 0.5 * np.arctan2(2*cov_xy, (cov_xx - cov_yy))
                    orient_deg = float(np.degrees(theta)) % 180
                else:
                    orient_deg = float('nan')
                rows.append({
                    'area_px': area,
                    'bbox_w': w_,
                    'bbox_h': h_,
                    'elongation': round(elong,3),
                    'orientation_deg': round(orient_deg,2)
                })
            return rows

        import pandas as _pd_alias
        metrics = {
            'è£‚ç¼': extract_components(mask_crack),
            'å‰¥è½': extract_components(mask_peel),
            'è¤ªè‰²': extract_components(mask_disc),
            'æ±¡æ¸/éœ‰æ–‘': extract_components(mask_stain),
            'ç›èš€/é£åŒ–': extract_components(mask_salt),
            'ç”Ÿç‰©é™„ç€': extract_components(mask_bio)
        }
        st.markdown("### ğŸ” ç»†åŒ–ç—…ç†æŒ‡æ ‡ï¼ˆæŒ‰ç±»åˆ«ï¼‰")
        cat_tabs = st.tabs(list(metrics.keys()))
        for tab, (cat, rows) in zip(cat_tabs, metrics.items()):
            with tab:
                if len(rows) == 0:
                    st.write("æ— æ˜¾è‘—è¿é€šåŸŸï¼ˆå—æœ€å°é¢ç§¯é˜ˆå€¼å½±å“ï¼‰")
                else:
                    df = _pd_alias.DataFrame(rows)
                    st.write(f"è¿é€šåŸŸæ•°é‡ï¼š{len(df)}ï¼Œé¢ç§¯ä¸­ä½æ•°ï¼š{df['area_px'].median():.0f} pxï¼Œç»†é•¿æ¯”P95ï¼š{df['elongation'].quantile(0.95):.2f}")
                    st.dataframe(df.sort_values('area_px', ascending=False).head(50), use_container_width=True)
                    csv = df.to_csv(index=False).encode('utf-8')
                    st.download_button(label=f"ä¸‹è½½{cat}æŒ‡æ ‡CSV", data=csv, file_name=f"metrics_{cat}.csv", mime="text/csv")

        # textual suggestions
        st.markdown("### ğŸ’¡ å»ºè®®ï¼ˆå¯¹ç—‡æ–¹æ¡ˆï¼‰")
        pct_map = {
            'crack': crack_pct,
            'peel': peel_pct,
            'disc': disc_pct,
            'stain': stain_pct,
            'salt': salt_pct,
            'bio': bio_pct
        }
        detailed_recs = build_recommendations(material, pct_map, severity)
        for r in detailed_recs:
            st.write(f"- {r}")

        # inpainting UI moved to a global section that uses cached masks

        # ---------------------
        # Time-comparison (if previous uploaded)
        # ---------------------
        if uploaded_prev:
            prev_bytes = np.asarray(bytearray(uploaded_prev.read()), dtype=np.uint8)
            prev_img = cv2.imdecode(prev_bytes, cv2.IMREAD_COLOR)
            if prev_img is None:
                st.warning("å†å²å›¾åƒæ— æ³•è¯»å–ï¼Œè¯·ç¡®è®¤æ–‡ä»¶æ ¼å¼ä¸å®Œæ•´æ€§ï¼Œå·²è·³è¿‡å†å²å¯¹æ¯”ã€‚")
            else:
                prev_img_proc, scale_prev = preprocess_image(prev_img.copy())
                prev_gray = cv2.cvtColor(prev_img_proc, cv2.COLOR_BGR2GRAY)
                prev_h, prev_w = prev_gray.shape
                # naive comparison: compare masks area difference (after resizing to match)
                # Resize prev masks to current shape if needed
                if prev_img_proc.shape[:2] != img_proc.shape[:2]:
                    prev_img_proc = cv2.resize(prev_img_proc, (img_proc.shape[1], img_proc.shape[0]))
                    prev_gray = cv2.cvtColor(prev_img_proc, cv2.COLOR_BGR2GRAY)
                # detect previous masks (same pipeline)
                p_boxes_crack, p_mask_crack = detect_cracks(prev_gray)
                p_hsv = cv2.cvtColor(prev_img_proc, cv2.COLOR_BGR2HSV)
                p_boxes_peel, p_mask_peel = detect_peeling(p_hsv)
                p_boxes_disc, p_mask_disc = detect_discoloration(p_hsv)
                # compute area change
                prev_crack_area = int(np.sum(p_mask_crack>0))
                prev_peel_area = int(np.sum(p_mask_peel>0))
                prev_disc_area = int(np.sum(p_mask_disc>0))
                st.markdown("### ğŸ•’ å†å²å¯¹æ¯”ç»“æœ")
                st.write(f"- è£‚ç¼é¢ç§¯å˜åŒ–ï¼š{prev_crack_area} -> {crack_area} ï¼ˆå·®å€¼ {crack_area - prev_crack_area} åƒç´ ï¼‰")
                st.write(f"- å‰¥è½é¢ç§¯å˜åŒ–ï¼š{prev_peel_area} -> {peel_area} ï¼ˆå·®å€¼ {peel_area - prev_peel_area} åƒç´ ï¼‰")
                st.write(f"- è¤ªè‰²é¢ç§¯å˜åŒ–ï¼š{prev_disc_area} -> {disc_area} ï¼ˆå·®å€¼ {disc_area - prev_disc_area} åƒç´ ï¼‰")
                # quick assessment
                if (crack_area - prev_crack_area) > (0.05 * total_pixels):
                    st.error("è£‚ç¼é¢ç§¯æ˜¾è‘—å¢åŠ ï¼Œå»ºè®®å°½å¿«å®åœ°è¯„ä¼°ã€‚")
                elif (peel_area - prev_peel_area) > (0.05 * total_pixels):
                    st.error("å‰¥è½é¢ç§¯æ˜¾è‘—å¢åŠ ï¼Œå¯èƒ½å­˜åœ¨è¿›å±•æ€§ç ´åã€‚")

        # ---------------------
        # Generate PDF with annotated image and results
        # ---------------------
        def generate_pdf_report(annotated_rgb, results, material, suggestions_text):
            """Create PDF and return bytesIO"""
            buf = BytesIO()
            doc = SimpleDocTemplate(buf, pagesize=A4)
            styles = getSampleStyleSheet()
            story = []
            story.append(Paragraph("çŸ³çªŸå¯ºå£ç”»ç—…å®³AIè¯Šæ–­æŠ¥å‘Šï¼ˆå‡çº§ç‰ˆï¼‰", styles['Title']))
            story.append(Spacer(1,6))
            story.append(Paragraph(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", styles['Normal']))
            story.append(Spacer(1,12))

            # insert annotated image (save to tmp buffer)
            img_buf = save_annotated_image_bytes(annotated_rgb)
            # reportlab needs a filename-like object; RLImage accepts BytesIO
            story.append(RLImage(img_buf, width=160*mm, height=(160*annotated_rgb.shape[0]/annotated_rgb.shape[1])*mm))
            story.append(Spacer(1,12))

            story.append(Paragraph("<b>ä¸€ã€é‡åŒ–ç»“æœ</b>", styles['Heading2']))
            for line in results:
                story.append(Paragraph(line, styles['Normal']))
            story.append(Spacer(1,8))

            story.append(Paragraph("<b>äºŒã€ç»¼åˆå»ºè®®</b>", styles['Heading2']))
            for line in suggestions_text:
                story.append(Paragraph(line, styles['Normal']))
            story.append(Spacer(1,12))

            if material != "æœªæŒ‡å®š":
                story.append(Paragraph("<b>ä¸‰ã€æè´¨ä¸“ç”¨å»ºè®®</b>", styles['Heading2']))
                for t in MATERIAL_SUGGESTIONS.get(material, []):
                    story.append(Paragraph(t, styles['Normal']))
                story.append(Spacer(1,8))

            story.append(Paragraph(f"Â© {datetime.now().year} ä¸Šæµ·äº¤å¤§æ–‡ç‰©ä¿®å¤å›¢é˜Ÿ | AI+æ–‡ç‰©ä¿æŠ¤ç ”ç©¶", styles['Normal']))
            doc.build(story)
            buf.seek(0)
            return buf

        results_lines = [
            f"è£‚ç¼è¦†ç›–é¢ç§¯ï¼š{crack_area} åƒç´ ï¼Œå æ¯” {crack_pct:.4f}%",
            f"å‰¥è½è¦†ç›–é¢ç§¯ï¼š{peel_area} åƒç´ ï¼Œå æ¯” {peel_pct:.4f}%",
            f"è¤ªè‰²è¦†ç›–é¢ç§¯ï¼š{disc_area} åƒç´ ï¼Œå æ¯” {disc_pct:.4f}%",
            f"æ±¡æ¸/éœ‰æ–‘è¦†ç›–é¢ç§¯ï¼š{stain_area} åƒç´ ï¼Œå æ¯” {stain_pct:.4f}%",
            f"ç›èš€/é£åŒ–è¦†ç›–é¢ç§¯ï¼š{salt_area} åƒç´ ï¼Œå æ¯” {salt_pct:.4f}%",
            f"ç”Ÿç‰©é™„ç€è¦†ç›–é¢ç§¯ï¼š{bio_area} åƒç´ ï¼Œå æ¯” {bio_pct:.4f}%",
            f"æ•´ä½“ä¸¥é‡åº¦è¯„åˆ†ï¼ˆ0-100ï¼‰ï¼š{severity}ï¼Œç­‰çº§ï¼š{lvl}"
        ]
        suggestions_text = detailed_recs

        pdf_buf = generate_pdf_report(annotated, results_lines, material, suggestions_text)
        st.download_button("â¬‡ï¸ ä¸‹è½½è¯Šæ–­æŠ¥å‘Šï¼ˆå«æ ‡æ³¨å›¾ï¼‰PDF", data=pdf_buf.getvalue(), file_name="è¯Šæ–­æŠ¥å‘Š_å£ç”».pdf", mime="application/pdf")

        # Cache results for interactive toggling without re-uploading
        st.session_state["proc"] = {
            'img_rgb': img_rgb,
            'masks': {
                'crack': mask_crack, 'peel': mask_peel, 'disc': mask_disc,
                'stain': mask_stain, 'salt': mask_salt, 'bio': mask_bio
            },
            'boxes': {
                'crack': boxes_crack, 'peel': boxes_peel, 'disc': boxes_disc,
                'stain': boxes_stain, 'salt': boxes_salt, 'bio': boxes_bio
            },
            'shape': gray.shape
        }

# footer
st.markdown(f"<div style='text-align:center;color:#666;margin-top:32px;'>Â© {datetime.now().year} ä¸Šæµ·äº¤å¤§æ–‡ç‰©ä¿®å¤å›¢é˜Ÿ | AI+æ–‡ç‰©ä¿æŠ¤ç ”ç©¶</div>", unsafe_allow_html=True)

# If cached results exist, allow re-render with current toggles without re-uploading
if st.session_state.get("proc") is not None and (uploaded is None or not analyze_btn):
    cache = st.session_state["proc"]
    img_rgb = cache['img_rgb']
    masks = cache['masks']
    boxes_map = cache['boxes']
    h, w = cache['shape']

    mask_crack = masks['crack']; mask_peel = masks['peel']; mask_disc = masks['disc']
    mask_stain = masks['stain']; mask_salt = masks['salt']; mask_bio = masks['bio']
    boxes_crack = boxes_map['crack']; boxes_peel = boxes_map['peel']; boxes_disc = boxes_map['disc']
    boxes_stain = boxes_map['stain']; boxes_salt = boxes_map['salt']; boxes_bio = boxes_map['bio']

    annotated = img_rgb.copy()
    def draw_boxes(boxes, color, visible, tag_text):
        if not visible or display_mode == "ä»…æ©è†œ":
            return
        for (x,y,w_,h_) in boxes:
            if w_*h_ < min_area:
                continue
            cv2.rectangle(annotated, (x,y), (x+w_, y+h_), color, 2)
            if show_labels:
                tx = x; ty = max(0, y-8)
                text = tag_text
                (tw, th), bl = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.45, 1)
                cv2.rectangle(annotated, (tx, ty-th-4), (tx+tw+4, ty+2), (0,0,0), -1)
                cv2.putText(annotated, text, (tx+2, ty-2), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 1, cv2.LINE_AA)

    if label_lang == "ä¸­æ–‡":
        crack_t, peel_t, disc_t, stain_t, salt_t, bio_t = "è£‚", "å‰¥", "è¤ª", "æ±¡", "ç›", "ç”Ÿ"
    else:
        crack_t, peel_t, disc_t, stain_t, salt_t, bio_t = "CR", "PL", "DC", "ST", "SA", "BIO"

    draw_boxes(boxes_crack, (255,0,0), show_crack, crack_t)
    draw_boxes(boxes_peel, (0,255,0), show_peel, peel_t)
    draw_boxes(boxes_disc, (0,0,255), show_disc, disc_t)
    draw_boxes(boxes_stain, (255,255,0), show_stain, stain_t)
    draw_boxes(boxes_salt, (0,255,255), show_salt, salt_t)
    draw_boxes(boxes_bio, (255,0,255), show_bio, bio_t)

    def overlay_mask(base_rgb, mask, color_rgb, alpha=0.35):
        overlay = base_rgb.copy()
        mask_bool = mask > 0
        overlay[mask_bool] = (overlay[mask_bool] * (1-alpha) + np.array(color_rgb) * alpha).astype(np.uint8)
        return overlay

    if display_mode in ("ä»…æ©è†œ", "è¾¹æ¡†+æ©è†œ"):
        if show_crack:
            annotated = overlay_mask(annotated, mask_crack, (255,0,0), alpha=0.25)
        if show_peel:
            annotated = overlay_mask(annotated, mask_peel, (0,255,0), alpha=0.18)
        if show_disc:
            annotated = overlay_mask(annotated, mask_disc, (0,0,255), alpha=0.18)
        if show_stain:
            annotated = overlay_mask(annotated, mask_stain, (255,255,0), alpha=0.20)
        if show_salt:
            annotated = overlay_mask(annotated, mask_salt, (0,255,255), alpha=0.18)
        if show_bio:
            annotated = overlay_mask(annotated, mask_bio, (255,0,255), alpha=0.20)

    st.subheader("åˆ†æç»“æœï¼ˆå¸¦æ ‡æ³¨ï¼‰")
    st.image(annotated, width='stretch')

    legend_html = """
    <div style='display:flex;flex-wrap:wrap;gap:12px;margin:6px 0 10px 0;'>
      <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#ff0000;'></span><span>è£‚ç¼</span></div>
      <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#00cc00;'></span><span>å‰¥è½</span></div>
      <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#0000ff;'></span><span>è¤ªè‰²</span></div>
      <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#ffff00;'></span><span>æ±¡æ¸/éœ‰æ–‘</span></div>
      <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#00ffff;'></span><span>ç›èš€/é£åŒ–</span></div>
      <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#ff00ff;'></span><span>ç”Ÿç‰©é™„ç€</span></div>
    </div>
    """
    st.markdown(legend_html, unsafe_allow_html=True)

    total_pixels = h*w
    crack_area = int(np.sum(mask_crack>0)); peel_area = int(np.sum(mask_peel>0)); disc_area = int(np.sum(mask_disc>0))
    stain_area = int(np.sum(mask_stain>0)); salt_area = int(np.sum(mask_salt>0)); bio_area = int(np.sum(mask_bio>0))

    crack_pct = crack_area / total_pixels * 100
    peel_pct = peel_area / total_pixels * 100
    disc_pct = disc_area / total_pixels * 100
    stain_pct = stain_area / total_pixels * 100
    salt_pct = salt_area / total_pixels * 100
    bio_pct = bio_area / total_pixels * 100

    weights = MATERIAL_WEIGHTS.get(material, MATERIAL_WEIGHTS["æœªæŒ‡å®š"])
    score = (
        weights.get('crack',1.0) * crack_pct * 1.8 +
        weights.get('peel',1.0) * peel_pct * 1.2 +
        weights.get('disc',1.0) * disc_pct * 1.5 +
        weights.get('stain',1.0) * stain_pct * 0.9 +
        weights.get('salt',1.0) * salt_pct * 1.6 +
        weights.get('bio',1.0) * bio_pct * 1.1
    )
    severity = min(round(score,1), 100.0)
    if severity < 5:
        lvl = "è½»å¾®"
    elif severity < 20:
        lvl = "ä¸­ç­‰"
    else:
        lvl = "ä¸¥é‡"

    st.markdown("### ğŸ“‹ é‡åŒ–ç»“æœ")
    st.write(f"- è£‚ç¼è¦†ç›–é¢ç§¯ï¼š{crack_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {crack_pct:.3f}%")
    st.write(f"- å‰¥è½è¦†ç›–é¢ç§¯ï¼š{peel_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {peel_pct:.3f}%")
    st.write(f"- è¤ªè‰²è¦†ç›–é¢ç§¯ï¼š{disc_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {disc_pct:.3f}%")
    st.write(f"- æ±¡æ¸/éœ‰æ–‘è¦†ç›–é¢ç§¯ï¼š{stain_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {stain_pct:.3f}%")
    st.write(f"- ç›èš€/é£åŒ–è¦†ç›–é¢ç§¯ï¼š{salt_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {salt_pct:.3f}%")
    st.write(f"- ç”Ÿç‰©é™„ç€è¦†ç›–é¢ç§¯ï¼š{bio_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {bio_pct:.3f}%")
    st.write(f"- æè´¨ï¼š**{material}**ï¼ˆç”¨äºè°ƒæ•´è¯„åˆ†ä¸å»ºè®®ï¼‰")
    st.metric("æ•´ä½“ç—…å®³ä¸¥é‡åº¦ï¼ˆ0-100ï¼‰", f"{severity}")

    st.markdown("### ğŸ’¡ å»ºè®®ï¼ˆå¯¹ç—‡æ–¹æ¡ˆï¼‰")
    pct_map = {'crack': crack_pct,'peel': peel_pct,'disc': disc_pct,'stain': stain_pct,'salt': salt_pct,'bio': bio_pct}
    detailed_recs = build_recommendations(material, pct_map, severity)
    for r in detailed_recs:
        st.write(f"- {r}")

    # ---------------------
    # Global inpainting (works with cached results)
    # ---------------------
    render_inpainting_ui(img_rgb, mask_crack, mask_peel, mask_disc, mask_stain, mask_salt, mask_bio, default_open=True, key_suffix="cached")