# app.py
import streamlit as st
import cv2
import numpy as np
import pandas as pd
from PIL import Image
from io import BytesIO
from datetime import datetime
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib.pagesizes import A4
from reportlab.lib.units import mm
import base64
import os
import sys
try:
    import onnxruntime as ort  # æ·±åº¦åˆ†å‰²æ¨ç†
except Exception:
    ort = None

# Optional deps for 3D
try:
    import open3d as o3d  # type: ignore
except Exception:
    o3d = None
try:
    import plotly.express as px
    import pandas as pd  # already imported above but for safety when 3D used
except Exception:
    px = None
try:
    from rapidocr_onnxruntime import RapidOCR  # è½»é‡OCRï¼ŒåŸºäº onnxruntime
except Exception:
    RapidOCR = None

# å¤šæ¨¡æ€èåˆç›¸å…³ä¾èµ–
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from transformers import AutoTokenizer, AutoModel
    import networkx as nx
    from sklearn.metrics.pairwise import cosine_similarity
    from sklearn.decomposition import PCA
    import json
    MULTIMODAL_AVAILABLE = True
except Exception:
    MULTIMODAL_AVAILABLE = False

st.set_page_config("çŸ³çªŸå¯ºå£ç”»ç—…å®³AIè¯†åˆ«å·¥å…·ï¼ˆå‡çº§ç‰ˆï¼‰", layout="wide", page_icon="ğŸ›ï¸")

# Session init
if "proc" not in st.session_state:
    st.session_state["proc"] = None

# ---------------------------
# åŠ¨æ€èƒŒæ™¯ä¸å“ç‰Œæ ‡è¯†
# ---------------------------

@st.cache_data(show_spinner=False)
def get_background_images_b64(dir_path: str = "assets/backgrounds"):
    exts = {".jpg", ".jpeg", ".png", ".webp"}
    images: list[str] = []
    try:
        if os.path.isdir(dir_path):
            for name in sorted(os.listdir(dir_path)):
                ext = os.path.splitext(name)[1].lower()
                if ext in exts:
                    full = os.path.join(dir_path, name)
                    with open(full, "rb") as f:
                        b64 = base64.b64encode(f.read()).decode("utf-8")
                        mime = "image/png" if ext == ".png" else ("image/webp" if ext == ".webp" else "image/jpeg")
                        images.append(f"data:{mime};base64,{b64}")
    except Exception:
        pass
    return images

@st.cache_data(show_spinner=False)
def get_logo_b64(candidates: list[str] = [
    "assets/sjtu_design.png", "assets/sjtu.png", "assets/logo_sjtu.png"
]):
    for p in candidates:
        try:
            if os.path.isfile(p):
                with open(p, "rb") as f:
                    b64 = base64.b64encode(f.read()).decode("utf-8")
                    ext = os.path.splitext(p)[1].lower()
                    mime = "image/png" if ext == ".png" else ("image/webp" if ext == ".webp" else "image/jpeg")
                    return f"data:{mime};base64,{b64}"
        except Exception:
            continue
    return None

def inject_dynamic_background(images_data_urls: list[str], interval_ms: int = 8000):
    if not images_data_urls:
        return
    imgs_js_array = ",".join([f"'" + u + "'" for u in images_data_urls])
    css = f"""
    <style>
    .stApp {{
        background-size: cover !important;
        background-position: center center !important;
        background-attachment: fixed !important;
        transition: background-image 1.2s ease-in-out;
    }}
    .bg-overlay::before {{
        content: "";
        position: fixed;
        inset: 0;
        background: radial-gradient(ellipse at center, rgba(0,0,0,0.25), rgba(0,0,0,0.45));
        pointer-events: none;
        z-index: 0;
    }}
    .app-brand-badge {{
        position: fixed;
        right: 16px;
        bottom: 16px;
        display: flex;
        align-items: center;
        gap: 10px;
        background: rgba(255,255,255,0.8);
        backdrop-filter: blur(6px);
        border-radius: 10px;
        padding: 8px 12px;
        box-shadow: 0 4px 16px rgba(0,0,0,0.15);
        z-index: 9999;
    }}
    .app-brand-badge img {{ height: 28px; width: auto; display:block; }}
    .app-brand-title {{ font-weight: 600; color: #333; font-size: 13px; line-height: 1.2; }}
    </style>
    """
    js = f"""
    <script>
    const bgImgs = [{imgs_js_array}];
    let idx = 0;
    function applyBg() {{
      const el = parent.document.querySelector('.stApp');
      if (!el) return;
      el.style.backgroundImage = `url(${bgImgs[idx]})`;
      idx = (idx + 1) % bgImgs.length;
    }}
    applyBg();
    if (!window.__bgInterval) {{
      window.__bgInterval = setInterval(applyBg, {interval_ms});
    }}
    const root = parent.document.querySelector('.stApp');
    if (root && !root.classList.contains('bg-overlay')) {{
      root.classList.add('bg-overlay');
    }}
    </script>
    """
    st.markdown(css + js, unsafe_allow_html=True)

def inject_brand_badge(logo_data_url: str | None):
    logo_img_html = f'<img src="{logo_data_url}" alt="SJTU" />' if logo_data_url else ""
    html = f"""
    <div class="app-brand-badge">
      {logo_img_html}
      <div class="app-brand-title">ä¸Šæµ·äº¤é€šå¤§å­¦<br/>è®¾è®¡å­¦é™¢</div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)

# ---------------------------
# å¤šæ¨¡æ€èåˆç³»ç»Ÿ
# ---------------------------

class KnowledgeGraph:
    """çŸ³çªŸç—…å®³çŸ¥è¯†å›¾è°±"""
    def __init__(self):
        self.graph = nx.DiGraph()
        self._build_knowledge_graph()
    
    def _build_knowledge_graph(self):
        """æ„å»ºçŸ³çªŸç±»å‹-æè´¨-å…¸å‹ç—…å®³-ä¿®å¤æ‰‹æ®µçŸ¥è¯†å›¾è°±"""
        # çŸ³çªŸç±»å‹èŠ‚ç‚¹
        cave_types = {
            "æ•¦ç…Œè«é«˜çªŸ": {"era": "åŒ—é­-å…ƒä»£", "climate": "å¹²æ—±", "structure": "ç ‚å²©"},
            "äº‘å†ˆçŸ³çªŸ": {"era": "åŒ—é­", "climate": "æ¸©å¸¦", "structure": "èŠ±å²—å²©"},
            "é¾™é—¨çŸ³çªŸ": {"era": "åŒ—é­-å”ä»£", "climate": "æ¸©å¸¦", "structure": "çŸ³ç°å²©"},
            "éº¦ç§¯å±±çŸ³çªŸ": {"era": "åç§¦-æ¸…ä»£", "climate": "æ¸©å¸¦", "structure": "æ³¥è´¨ç ‚å²©"}
        }
        
        # æè´¨èŠ‚ç‚¹
        materials = {
            "ç ‚å²©": {"porosity": "é«˜", "hardness": "ä¸­", "weathering": "æ˜“é£åŒ–"},
            "èŠ±å²—å²©": {"porosity": "ä½", "hardness": "é«˜", "weathering": "æŠ—é£åŒ–"},
            "çŸ³ç°å²©": {"porosity": "ä¸­", "hardness": "ä¸­", "weathering": "æ˜“æº¶èš€"},
            "æ³¥è´¨ç ‚å²©": {"porosity": "é«˜", "hardness": "ä½", "weathering": "ææ˜“é£åŒ–"}
        }
        
        # ç—…å®³èŠ‚ç‚¹
        pathologies = {
            "è¡¨é¢è£‚ç¼": {"severity": "ä¸­", "depth": "æµ…å±‚", "cause": "æ¸©å·®åº”åŠ›"},
            "æ·±å±‚è£‚ç¼": {"severity": "é«˜", "depth": "æ·±å±‚", "cause": "ç»“æ„åº”åŠ›"},
            "å‰¥è½": {"severity": "é«˜", "depth": "è¡¨é¢", "cause": "é£åŒ–"},
            "å˜è‰²": {"severity": "ä½", "depth": "è¡¨é¢", "cause": "æ°§åŒ–"},
            "ç›æ": {"severity": "ä¸­", "depth": "è¡¨é¢", "cause": "ç›åˆ†ç»“æ™¶"},
            "ç”Ÿç‰©ä¾µèš€": {"severity": "ä¸­", "depth": "è¡¨é¢", "cause": "å¾®ç”Ÿç‰©"}
        }
        
        # ä¿®å¤æ‰‹æ®µèŠ‚ç‚¹
        treatments = {
            "è¡¨é¢åŠ å›º": {"cost": "ä½", "effectiveness": "ä¸­", "durability": "çŸ­"},
            "æ·±å±‚æ³¨æµ†": {"cost": "é«˜", "effectiveness": "é«˜", "durability": "é•¿"},
            "è¡¨é¢æ¸…æ´—": {"cost": "ä½", "effectiveness": "é«˜", "durability": "çŸ­"},
            "ä¿æŠ¤æ¶‚å±‚": {"cost": "ä¸­", "effectiveness": "ä¸­", "durability": "ä¸­"},
            "ç¯å¢ƒæ§åˆ¶": {"cost": "é«˜", "effectiveness": "é«˜", "durability": "é•¿"}
        }
        
        # æ„å»ºå›¾ç»“æ„
        for cave, props in cave_types.items():
            self.graph.add_node(cave, type="cave", **props)
        
        for material, props in materials.items():
            self.graph.add_node(material, type="material", **props)
        
        for pathology, props in pathologies.items():
            self.graph.add_node(pathology, type="pathology", **props)
        
        for treatment, props in treatments.items():
            self.graph.add_node(treatment, type="treatment", **props)
        
        # æ·»åŠ å…³ç³»è¾¹
        relationships = [
            # çŸ³çªŸ-æè´¨å…³ç³»
            ("æ•¦ç…Œè«é«˜çªŸ", "ç ‚å²©", {"compatibility": "é«˜"}),
            ("äº‘å†ˆçŸ³çªŸ", "èŠ±å²—å²©", {"compatibility": "é«˜"}),
            ("é¾™é—¨çŸ³çªŸ", "çŸ³ç°å²©", {"compatibility": "é«˜"}),
            ("éº¦ç§¯å±±çŸ³çªŸ", "æ³¥è´¨ç ‚å²©", {"compatibility": "é«˜"}),
            
            # æè´¨-ç—…å®³å…³ç³»
            ("ç ‚å²©", "è¡¨é¢è£‚ç¼", {"probability": 0.8}),
            ("ç ‚å²©", "å‰¥è½", {"probability": 0.9}),
            ("èŠ±å²—å²©", "æ·±å±‚è£‚ç¼", {"probability": 0.6}),
            ("çŸ³ç°å²©", "ç›æ", {"probability": 0.7}),
            ("æ³¥è´¨ç ‚å²©", "å‰¥è½", {"probability": 0.95}),
            ("æ³¥è´¨ç ‚å²©", "ç”Ÿç‰©ä¾µèš€", {"probability": 0.8}),
            
            # ç—…å®³-ä¿®å¤å…³ç³»
            ("è¡¨é¢è£‚ç¼", "è¡¨é¢åŠ å›º", {"suitability": 0.9}),
            ("æ·±å±‚è£‚ç¼", "æ·±å±‚æ³¨æµ†", {"suitability": 0.95}),
            ("å‰¥è½", "è¡¨é¢åŠ å›º", {"suitability": 0.8}),
            ("å˜è‰²", "è¡¨é¢æ¸…æ´—", {"suitability": 0.9}),
            ("ç›æ", "è¡¨é¢æ¸…æ´—", {"suitability": 0.85}),
            ("ç”Ÿç‰©ä¾µèš€", "è¡¨é¢æ¸…æ´—", {"suitability": 0.8}),
        ]
        
        for source, target, attrs in relationships:
            self.graph.add_edge(source, target, **attrs)
    
    def query_treatment(self, cave_type, material, pathologies):
        """æ ¹æ®çŸ³çªŸç±»å‹ã€æè´¨å’Œç—…å®³æŸ¥è¯¢æœ€ä½³ä¿®å¤æ–¹æ¡ˆ"""
        treatments = []
        for pathology in pathologies:
            # æŸ¥æ‰¾è¯¥ç—…å®³çš„ä¿®å¤æ–¹æ¡ˆ
            for treatment in self.graph.successors(pathology):
                if self.graph.nodes[treatment]["type"] == "treatment":
                    suitability = self.graph[pathology][treatment].get("suitability", 0.5)
                    treatments.append({
                        "pathology": pathology,
                        "treatment": treatment,
                        "suitability": suitability,
                        "cost": self.graph.nodes[treatment]["cost"],
                        "effectiveness": self.graph.nodes[treatment]["effectiveness"],
                        "durability": self.graph.nodes[treatment]["durability"]
                    })
        
        # æŒ‰é€‚ç”¨æ€§æ’åº
        treatments.sort(key=lambda x: x["suitability"], reverse=True)
        return treatments

class MultimodalFusion:
    """å¤šæ¨¡æ€èåˆç³»ç»Ÿ"""
    def __init__(self):
        self.knowledge_graph = KnowledgeGraph()
        self.text_encoder = None
        self.image_encoder = None
        self.pointcloud_encoder = None
        self._init_encoders()
    
    def _init_encoders(self):
        """åˆå§‹åŒ–å„æ¨¡æ€ç¼–ç å™¨"""
        if not MULTIMODAL_AVAILABLE:
            return
        
        try:
            # æ–‡æœ¬ç¼–ç å™¨ï¼ˆä½¿ç”¨é¢„è®­ç»ƒçš„ä¸­æ–‡BERTï¼‰
            self.text_tokenizer = AutoTokenizer.from_pretrained("bert-base-chinese")
            self.text_encoder = AutoModel.from_pretrained("bert-base-chinese")
        except:
            st.warning("æ–‡æœ¬ç¼–ç å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
    
    def encode_image(self, image):
        """å›¾åƒç‰¹å¾ç¼–ç """
        if image is None:
            return None
        
        # ä½¿ç”¨é¢„è®­ç»ƒçš„ResNetç‰¹å¾
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
        features = cv2.resize(image, (224, 224))
        features = cv2.cvtColor(features, cv2.COLOR_BGR2RGB)
        features = features.flatten()[:512]  # ç®€åŒ–ç‰¹å¾
        return features / np.linalg.norm(features)
    
    def encode_pointcloud(self, pointcloud):
        """ç‚¹äº‘ç‰¹å¾ç¼–ç """
        if pointcloud is None or o3d is None:
            return None
        
        # è®¡ç®—ç‚¹äº‘å‡ ä½•ç‰¹å¾
        features = []
        
        # å¯†åº¦ç‰¹å¾
        if len(pointcloud.points) > 0:
            bbox = pointcloud.get_axis_aligned_bounding_box()
            volume = bbox.volume()
            density = len(pointcloud.points) / max(volume, 1e-6)
            features.append(density)
        else:
            features.append(0)
        
        # è¡¨é¢ç²—ç³™åº¦ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
        if len(pointcloud.points) > 10:
            points = np.asarray(pointcloud.points)
            distances = np.linalg.norm(points - np.mean(points, axis=0), axis=1)
            roughness = np.std(distances)
            features.append(roughness)
        else:
            features.append(0)
        
        # æ³•å‘é‡åˆ†å¸ƒï¼ˆç®€åŒ–ï¼‰
        if hasattr(pointcloud, 'normals') and len(pointcloud.normals) > 0:
            normals = np.asarray(pointcloud.normals)
            normal_std = np.std(normals, axis=0)
            features.extend(normal_std.tolist())
        else:
            features.extend([0, 0, 0])
        
        # å¡«å……åˆ°å›ºå®šé•¿åº¦
        while len(features) < 64:
            features.append(0)
        
        features = np.array(features[:64])
        return features / (np.linalg.norm(features) + 1e-8)
    
    def encode_text(self, text):
        """æ–‡æœ¬ç‰¹å¾ç¼–ç """
        if not text or self.text_encoder is None:
            return None
        
        try:
            inputs = self.text_tokenizer(text, return_tensors="pt", max_length=512, truncation=True)
            with torch.no_grad():
                outputs = self.text_encoder(**inputs)
                features = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()
            return features
        except:
            # ç®€åŒ–æ–‡æœ¬ç¼–ç 
            words = text.split()
            features = np.zeros(768)
            for i, word in enumerate(words[:10]):  # åªå–å‰10ä¸ªè¯
                features[i*77:(i+1)*77] = np.random.randn(77)  # ç®€åŒ–å¤„ç†
            return features / (np.linalg.norm(features) + 1e-8)
    
    def fuse_modalities(self, image_features, pointcloud_features, text_features):
        """å¤šæ¨¡æ€ç‰¹å¾èåˆ"""
        features = []
        
        if image_features is not None:
            features.append(image_features)
        if pointcloud_features is not None:
            features.append(pointcloud_features)
        if text_features is not None:
            features.append(text_features)
        
        if not features:
            return None
        
        # ç®€å•æ‹¼æ¥èåˆï¼ˆå®é™…åº”è¯¥ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶ï¼‰
        fused = np.concatenate(features)
        return fused / (np.linalg.norm(fused) + 1e-8)
    
    def analyze_depth_stability(self, image, pointcloud, crack_mask):
        """ç»“åˆç‚¹äº‘åˆ†æè£‚ç¼æ·±åº¦å’Œç»“æ„ç¨³å®šæ€§"""
        if pointcloud is None or o3d is None:
            return {"depth": "unknown", "stability": "unknown", "confidence": 0.0}
        
        try:
            # æå–è£‚ç¼åŒºåŸŸçš„ç‚¹äº‘
            points = np.asarray(pointcloud.points)
            if len(points) == 0:
                return {"depth": "unknown", "stability": "unknown", "confidence": 0.0}
            
            # è®¡ç®—è£‚ç¼æ·±åº¦ï¼ˆç®€åŒ–ç®—æ³•ï¼‰
            z_coords = points[:, 2]  # å‡è®¾Zè½´æ˜¯æ·±åº¦
            depth_variance = np.var(z_coords)
            
            # è®¡ç®—ç»“æ„ç¨³å®šæ€§æŒ‡æ ‡
            bbox = pointcloud.get_axis_aligned_bounding_box()
            volume = bbox.volume()
            point_density = len(points) / max(volume, 1e-6)
            
            # åŸºäºå‡ ä½•ç‰¹å¾åˆ¤æ–­
            if depth_variance > 0.1:
                depth = "deep"
                stability = "unstable"
            elif depth_variance > 0.05:
                depth = "medium"
                stability = "moderate"
            else:
                depth = "shallow"
                stability = "stable"
            
            confidence = min(point_density * 10, 1.0)
            
            return {
                "depth": depth,
                "stability": stability,
                "confidence": confidence,
                "depth_variance": depth_variance,
                "point_density": point_density
            }
        except Exception as e:
            return {"depth": "error", "stability": "error", "confidence": 0.0, "error": str(e)}

class AutoAnnotator:
    """LLMè‡ªåŠ¨æ ‡æ³¨ç³»ç»Ÿ"""
    def __init__(self):
        self.annotation_templates = {
            "crack": {
                "description": "è£‚ç¼ç—…å®³ï¼Œé€šå¸¸è¡¨ç°ä¸ºçº¿æ€§ç¼ºé™·",
                "severity_levels": ["è½»å¾®", "ä¸­ç­‰", "ä¸¥é‡"],
                "key_features": ["çº¿æ€§", "è¿ç»­æ€§", "æ·±åº¦å˜åŒ–"]
            },
            "peel": {
                "description": "å‰¥è½ç—…å®³ï¼Œè¡¨é¢ææ–™è„±è½",
                "severity_levels": ["è½»å¾®", "ä¸­ç­‰", "ä¸¥é‡"],
                "key_features": ["ä¸è§„åˆ™å½¢çŠ¶", "è¾¹ç¼˜æ¸…æ™°", "åšåº¦å˜åŒ–"]
            },
            "discolor": {
                "description": "å˜è‰²ç—…å®³ï¼Œé¢œè‰²å¼‚å¸¸å˜åŒ–",
                "severity_levels": ["è½»å¾®", "ä¸­ç­‰", "ä¸¥é‡"],
                "key_features": ["é¢œè‰²å·®å¼‚", "è¾¹ç•Œæ¨¡ç³Š", "é¢ç§¯åˆ†å¸ƒ"]
            }
        }
    
    def generate_annotation(self, image, detected_regions, defect_type):
        """åŸºäºæ£€æµ‹ç»“æœç”Ÿæˆè‡ªåŠ¨æ ‡æ³¨"""
        if defect_type not in self.annotation_templates:
            return None
        
        template = self.annotation_templates[defect_type]
        annotations = []
        
        for region in detected_regions:
            # è®¡ç®—åŒºåŸŸç‰¹å¾
            area = region.get("area", 0)
            bbox = region.get("bbox", [0, 0, 0, 0])
            elongation = region.get("elongation", 0)
            
            # åŸºäºç‰¹å¾åˆ¤æ–­ä¸¥é‡ç¨‹åº¦
            if area > 1000:
                severity = "ä¸¥é‡"
            elif area > 500:
                severity = "ä¸­ç­‰"
            else:
                severity = "è½»å¾®"
            
            # ç”Ÿæˆæ ‡æ³¨æ–‡æœ¬
            annotation = {
                "type": defect_type,
                "description": template["description"],
                "severity": severity,
                "area": area,
                "bbox": bbox,
                "confidence": 0.8,  # ç®€åŒ–ç½®ä¿¡åº¦
                "features": {
                    "elongation": elongation,
                    "aspect_ratio": bbox[2] / max(bbox[3], 1),
                    "area_ratio": area / (image.shape[0] * image.shape[1])
                }
            }
            annotations.append(annotation)
        
        return annotations

class GenerativeAugmentation:
    """ç”Ÿæˆå¼å¢å¼ºï¼šè™šæ‹Ÿä¿®å¤"""
    def __init__(self):
        self.restoration_templates = {
            "crack": {
                "method": "inpainting",
                "parameters": {"algorithm": "telea", "radius": 3}
            },
            "peel": {
                "method": "texture_synthesis",
                "parameters": {"patch_size": 32, "overlap": 8}
            },
            "discolor": {
                "method": "color_correction",
                "parameters": {"method": "reinhard", "target": "reference"}
            }
        }
    
    def virtual_restoration(self, image, mask, defect_type):
        """è™šæ‹Ÿä¿®å¤æ¨¡æ‹Ÿ"""
        if defect_type not in self.restoration_templates:
            return image
        
        template = self.restoration_templates[defect_type]
        
        if template["method"] == "inpainting":
            # ä½¿ç”¨OpenCVä¿®å¤
            result = cv2.inpaint(image, mask, 3, cv2.INPAINT_TELEA)
        elif template["method"] == "color_correction":
            # é¢œè‰²æ ¡æ­£
            result = self._color_correction(image, mask)
        else:
            result = image
        
        return result
    
    def _color_correction(self, image, mask):
        """é¢œè‰²æ ¡æ­£"""
        # ç®€åŒ–é¢œè‰²æ ¡æ­£
        result = image.copy()
        mask_3ch = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
        
        # åŸºäºå‘¨å›´åŒºåŸŸçš„é¢œè‰²è¿›è¡Œæ ¡æ­£
        kernel = np.ones((5, 5), np.uint8)
        mask_dilated = cv2.dilate(mask, kernel, iterations=2)
        mask_eroded = cv2.erode(mask, kernel, iterations=2)
        border_mask = mask_dilated - mask_eroded
        
        if np.sum(border_mask) > 0:
            # è®¡ç®—è¾¹ç•ŒåŒºåŸŸçš„å¹³å‡é¢œè‰²
            border_pixels = image[border_mask > 0]
            if len(border_pixels) > 0:
                mean_color = np.mean(border_pixels, axis=0)
                result[mask > 0] = mean_color
        
        return result

# å…¨å±€å¤šæ¨¡æ€ç³»ç»Ÿå®ä¾‹
@st.cache_resource
def get_multimodal_system():
    return MultimodalFusion()

@st.cache_resource
def get_auto_annotator():
    return AutoAnnotator()

@st.cache_resource
def get_generative_augmentation():
    return GenerativeAugmentation()

# ---------------------------
# Caching helpers
# ---------------------------
@st.cache_resource(show_spinner=False)
def get_onnx_session_cached(model_path: str, providers):
    return ort.InferenceSession(model_path, providers=providers)

@st.cache_data(show_spinner=False)
def _resize_bgr_cached(image_bgr_bytes: bytes, w: int, h: int):
    arr = np.frombuffer(image_bgr_bytes, dtype=np.uint8)
    img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    if img is None:
        raise ValueError("æ— æ³•ä»ç¼“å­˜å­—èŠ‚è§£ç å›¾åƒ")
    return cv2.resize(img, (w, h), interpolation=cv2.INTER_AREA)

@st.cache_resource(show_spinner=False)
def get_rapidocr_cached():
    if RapidOCR is None:
        return None
    try:
        return RapidOCR()
    except Exception:
        return None

# ---------------------------
# Helpers: render inpainting UI
# ---------------------------
def render_inpainting_ui(img_rgb, mask_crack, mask_peel, mask_disc, mask_stain, mask_salt, mask_bio, default_open=True, key_suffix=""):
    st.markdown("### ğŸ§© å›¾åƒå¤åŸï¼ˆè¯•éªŒæ€§ Inpaintingï¼‰")
    with st.expander("å±•å¼€/æ”¶èµ·", expanded=default_open):
        sel_classes = st.multiselect(
            "é€‰æ‹©éœ€è¦å¤åŸçš„ç—…å®³ç±»åˆ«ï¼ˆå°†åŸºäºå…¶æ©è†œè¿›è¡Œä¿®è¡¥ï¼‰",
            ["è£‚ç¼","å‰¥è½","è¤ªè‰²","æ±¡æ¸/éœ‰æ–‘","ç›èš€/é£åŒ–","ç”Ÿç‰©é™„ç€"],
            default=["è£‚ç¼","å‰¥è½","æ±¡æ¸/éœ‰æ–‘"], key=f"sel_classes_{key_suffix}"
        )
        method = st.selectbox("ä¿®è¡¥ç®—æ³•", ["Telea", "Navier-Stokes"], index=0, key=f"method_{key_suffix}")
        radius = st.slider("ä¿®è¡¥åŠå¾„ï¼ˆåƒç´ ï¼‰", min_value=1, max_value=25, value=7, key=f"radius_{key_suffix}")
        go_restore = st.button("ç”Ÿæˆå¤åŸå›¾åƒ", key=f"restore_btn_{key_suffix}")
        if go_restore:
            class_to_mask = {
                "è£‚ç¼": mask_crack,
                "å‰¥è½": mask_peel,
                "è¤ªè‰²": mask_disc,
                "æ±¡æ¸/éœ‰æ–‘": mask_stain,
                "ç›èš€/é£åŒ–": mask_salt,
                "ç”Ÿç‰©é™„ç€": mask_bio,
            }
            union = np.zeros(mask_crack.shape, dtype=np.uint8)
            for c in sel_classes:
                m = class_to_mask.get(c)
                if m is not None:
                    union = cv2.bitwise_or(union, (m>0).astype(np.uint8)*255)
            num_labels, labels, stats, _ = cv2.connectedComponentsWithStats((union>0).astype(np.uint8), connectivity=8)
            filtered = np.zeros_like(union)
            for i in range(1, num_labels):
                area = int(stats[i, cv2.CC_STAT_AREA])
                if area >= 50:
                    filtered[labels==i] = 255
            flag = cv2.INPAINT_TELEA if method == "Telea" else cv2.INPAINT_NS
            src_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
            restored_bgr = cv2.inpaint(src_bgr, (filtered>0).astype(np.uint8), radius, flag)
            restored_rgb = cv2.cvtColor(restored_bgr, cv2.COLOR_BGR2RGB)
            st.image(restored_rgb, caption="å¤åŸç»“æœï¼ˆåŸºäºæ‰€é€‰æ©è†œï¼‰", width='stretch')
            _buf = BytesIO(); Image.fromarray(restored_rgb).save(_buf, format="PNG"); _buf.seek(0)
            st.download_button("ä¸‹è½½å¤åŸå›¾ï¼ˆPNGï¼‰", data=_buf.getvalue(), file_name="restored.png", mime="image/png")

# ---------------------------
# Helpers: color restoration utilities
# ---------------------------
def _to_bgr(img_rgb):
    return cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

def _to_rgb(img_bgr):
    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

def gray_world_white_balance(img_bgr):
    img = img_bgr.astype(np.float32)
    mean_b, mean_g, mean_r = [np.mean(img[:,:,c]) for c in range(3)]
    mean_gray = (mean_b + mean_g + mean_r) / 3.0
    gain_b = mean_gray / (mean_b + 1e-6)
    gain_g = mean_gray / (mean_g + 1e-6)
    gain_r = mean_gray / (mean_r + 1e-6)
    img[:,:,0] = np.clip(img[:,:,0] * gain_b, 0, 255)
    img[:,:,1] = np.clip(img[:,:,1] * gain_g, 0, 255)
    img[:,:,2] = np.clip(img[:,:,2] * gain_r, 0, 255)
    return img.astype(np.uint8)

def clahe_on_l_channel(img_bgr, clip_limit=2.0, tile_grid_size=8):
    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=float(clip_limit), tileGridSize=(int(tile_grid_size), int(tile_grid_size)))
    l2 = clahe.apply(l)
    lab2 = cv2.merge([l2, a, b])
    return cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR)

def reinhard_color_transfer(src_bgr, ref_bgr):
    # Convert to LAB and match mean/std
    src_lab = cv2.cvtColor(src_bgr, cv2.COLOR_BGR2LAB).astype(np.float32)
    ref_lab = cv2.cvtColor(ref_bgr, cv2.COLOR_BGR2LAB).astype(np.float32)
    for c in range(3):
        s_mean, s_std = src_lab[:,:,c].mean(), src_lab[:,:,c].std() + 1e-6
        r_mean, r_std = ref_lab[:,:,c].mean(), ref_lab[:,:,c].std() + 1e-6
        src_lab[:,:,c] = (src_lab[:,:,c] - s_mean) * (r_std / s_std) + r_mean
    src_lab = np.clip(src_lab, 0, 255).astype(np.uint8)
    return cv2.cvtColor(src_lab, cv2.COLOR_LAB2BGR)

def render_color_restore_ui(img_rgb, default_open=False, key_suffix="color"):
    st.markdown("### ğŸ¨ è‰²å½©/è¤ªè‰²å¤åŸï¼ˆåŸºç¡€ç‰ˆï¼‰")
    with st.expander("å±•å¼€/æ”¶èµ·", expanded=default_open):
        col1, col2 = st.columns(2)
        with col1:
            use_wb = st.checkbox("ç°åº¦ä¸–ç•Œç™½å¹³è¡¡", value=True, key=f"wb_{key_suffix}")
            clahe_clip = st.slider("CLAHE å¯¹æ¯”åº¦ (clip)", 0.0, 4.0, 2.0, 0.1, key=f"clip_{key_suffix}")
            clahe_tile = st.slider("CLAHE ç½‘æ ¼", 4, 16, 8, 1, key=f"tile_{key_suffix}")
        with col2:
            ref_file = st.file_uploader("å‚è€ƒå›¾åƒï¼ˆå¯é€‰ï¼Œç”¨äºé£æ ¼/è‰²å½©è½¬ç§»ï¼‰", type=["jpg","jpeg","png"], key=f"ref_{key_suffix}")
            do_transfer = st.checkbox("å¯ç”¨å‚è€ƒè‰²å½©è½¬ç§»ï¼ˆReinhardï¼‰", value=False, key=f"tr_{key_suffix}")
        run_color = st.button("ç”Ÿæˆè‰²å½©å¤åŸå›¾", key=f"btn_{key_suffix}")
        if run_color:
            bgr = _to_bgr(img_rgb)
            out = bgr
            if use_wb:
                out = gray_world_white_balance(out)
            out = clahe_on_l_channel(out, clip_limit=clahe_clip, tile_grid_size=clahe_tile)
            if do_transfer and ref_file is not None:
                ref_bytes = np.asarray(bytearray(ref_file.read()), dtype=np.uint8)
                ref_bgr = cv2.imdecode(ref_bytes, cv2.IMREAD_COLOR)
                if ref_bgr is not None:
                    out = reinhard_color_transfer(out, ref_bgr)
            rgb = _to_rgb(out)
            st.image(rgb, caption="è‰²å½©å¤åŸç»“æœ", width='stretch')
            buf = BytesIO(); Image.fromarray(rgb).save(buf, format="PNG"); buf.seek(0)
            st.download_button("ä¸‹è½½å¤åŸå›¾ï¼ˆPNGï¼‰", data=buf.getvalue(), file_name="restored_color.png", mime="image/png")

# ---------------------------
# Utility helpers
# ---------------------------
def pil_from_cv2(cv2_img):
    """BGR or RGB? we expect RGB input"""
    if len(cv2_img.shape) == 3:
        return Image.fromarray(cv2_img)
    else:
        return Image.fromarray(cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB))

def encode_image_to_bytes(img_rgb):
    """PIL Image -> bytes"""
    buf = BytesIO()
    img_rgb.save(buf, format="PNG")
    buf.seek(0)
    return buf

def save_annotated_image_bytes(annotated_rgb):
    """Return bytesIO for embedding to reportlab or streamlit download"""
    pil = Image.fromarray(annotated_rgb)
    buf = BytesIO()
    pil.save(buf, format="PNG")
    buf.seek(0)
    return buf

# ---------------------------
# Material-specific parameters
# ---------------------------
MATERIAL_OPTIONS = [
    "æœªæŒ‡å®š",
    "å¤§è¶³çŸ³åˆ»ï¼ˆç ‚å²©ï¼‰",
    "äº‘å†ˆçŸ³çªŸï¼ˆç ‚å²©å¤¹æ³¥å²©ï¼‰",
    "æ•¦ç…Œè«é«˜çªŸï¼ˆç°æ³¥/é¢œæ–™å±‚ï¼‰",
    "æœ¨è´¨åŸºåº•ï¼ˆæœ¨æ¿ï¼‰"
]

MATERIAL_WEIGHTS = {
    # weights for severity scoring per category
    # categories: crack, peel, disc, stain, salt, bio
    "æœªæŒ‡å®š": {
        "crack": 1.0, "peel": 1.0, "disc": 1.0, "stain": 0.9, "salt": 1.0, "bio": 0.8
    },
    "å¤§è¶³çŸ³åˆ»ï¼ˆç ‚å²©ï¼‰": {
        "crack": 1.2, "peel": 1.3, "disc": 0.9, "stain": 0.9, "salt": 1.4, "bio": 0.8
    },
    "äº‘å†ˆçŸ³çªŸï¼ˆç ‚å²©å¤¹æ³¥å²©ï¼‰": {
        "crack": 1.3, "peel": 1.2, "disc": 1.0, "stain": 0.9, "salt": 1.3, "bio": 0.8
    },
    "æ•¦ç…Œè«é«˜çªŸï¼ˆç°æ³¥/é¢œæ–™å±‚ï¼‰": {
        "crack": 1.0, "peel": 1.1, "disc": 1.4, "stain": 1.1, "salt": 0.9, "bio": 0.8
    },
    "æœ¨è´¨åŸºåº•ï¼ˆæœ¨æ¿ï¼‰": {
        "crack": 1.1, "peel": 1.2, "disc": 1.0, "stain": 1.2, "salt": 0.6, "bio": 1.3
    }
}

MATERIAL_SUGGESTIONS = {
    "å¤§è¶³çŸ³åˆ»ï¼ˆç ‚å²©ï¼‰": [
        "ç ‚å²©è´¨åœ°ç–æ¾ï¼Œä¼˜å…ˆé˜²æ°´åŠ å›ºã€é˜²æ­¢ç›æä¸å´©è§£ã€‚",
        "é’ˆå¯¹å¤§é¢ç§¯å‰¥è½ï¼Œå»ºè®®è¿›è¡Œç‰©ç†åŠ å›ºä¸æ³¨æµ†ã€‚"
    ],
    "äº‘å†ˆçŸ³çªŸï¼ˆç ‚å²©å¤¹æ³¥å²©ï¼‰": [
        "æ§åˆ¶æ´çªŸæ¹¿åº¦ï¼Œæ£€æŸ¥å¤¹å±‚æ°´æ¸—ã€é‡‡å–æ³¨æµ†æˆ–æ”¯æ’‘åŠ å›ºã€‚",
        "æ³¨æ„è£‚ç¼æ³¨å…¥å’Œè£‚ç¼æ‰©å±•çš„ç›‘æµ‹ã€‚"
    ],
    "æ•¦ç…Œè«é«˜çªŸï¼ˆç°æ³¥/é¢œæ–™å±‚ï¼‰": [
        "é‡ç‚¹ä¿æŠ¤é¢œæ–™å±‚ï¼Œé¿å…ç›´æ¥è§¦æ‘¸ä¸æ¹¿çƒ­ç¯å¢ƒå˜åŠ¨ã€‚",
        "å¯¹äºèµ·ç”²ä¸é¢œæ–™è„±è½ï¼Œåº”é‡‡ç”¨å¯é€†æ€§ä¿®å¤ææ–™ä¼˜å…ˆã€‚"
    ],
    "æœ¨è´¨åŸºåº•ï¼ˆæœ¨æ¿ï¼‰": [
        "å…³æ³¨è™«è›€ã€éœ‰èŒä¸å«æ°´ç‡å˜åŒ–ï¼Œå¿…è¦æ—¶è¿›è¡Œé˜²è™«ä¸é™¤æ¹¿å¤„ç†ã€‚",
        "é¿å…å¼ºå…‰ç›´å°„ä¸å¤§å¹…æ¸©æ¹¿å˜åŒ–ï¼Œè¡¨å±‚å»ºè®®ä½¿ç”¨å¯é€†æ€§ä¿æŠ¤æ¶‚å±‚ã€‚"
    ]
}

# ç»†åŒ–ï¼šæŒ‰ç—…å®³ç±»å‹å’Œæ¯”ä¾‹ç”Ÿæˆå»ºè®®
def build_recommendations(material, pct_map, overall_severity):
    recs = []
    m = material
    cp = pct_map.get('crack', 0.0)
    pp = pct_map.get('peel', 0.0)
    dp = pct_map.get('disc', 0.0)
    sp = pct_map.get('stain', 0.0)
    sap = pct_map.get('salt', 0.0)
    bp = pct_map.get('bio', 0.0)

    # è£‚ç¼
    if cp > 0.1:
        if cp < 1:
            recs.append("è£‚ç¼è½»åº¦ï¼šå»ºè®®è£‚ç¼ç›‘æµ‹ä¸è®°å½•ï¼Œé¿å…éœ‡åŠ¨ä¸å¹²æ¹¿å˜åŠ¨ï¼›å¿…è¦æ—¶è¡¨é¢åŠ å›ºã€‚")
        elif cp < 5:
            recs.append("è£‚ç¼ä¸­åº¦ï¼šè¿›è¡Œè£‚ç¼èµ°å‘/å®½åº¦æµ‹é‡ä¸å®šæœŸå¤æµ‹ï¼›å¯é‡‡ç”¨å¾®æ³¨æµ†æˆ–ä½é»åº¦åŠ å›ºæ ‘è„‚ï¼ˆå¯é€†/ä½æŒ¥å‘ï¼‰è¿›è¡Œå¡«å……ä¸åŠ å›ºã€‚")
        else:
            recs.append("è£‚ç¼é‡åº¦ï¼šä¼˜å…ˆå®æ–½ç»“æ„åŠ å›ºï¼ˆæ”¯æ’‘/é”šå›º/æ³¨æµ†ï¼‰ï¼Œå¹¶æŸ¥æ˜è‡´å› ï¼ˆæ¸—æ°´ã€æ¸©å˜ã€åº”åŠ›ï¼‰ï¼ŒåŒæ­¥å¼€å±•é•¿æœŸç›‘æµ‹ã€‚")
        if "æœ¨è´¨" in m:
            recs.append("æœ¨è´¨æ³¨æ„ï¼šä¼˜å…ˆæ§åˆ¶å«æ°´ç‡ä¸æ¸©æ¹¿ç¨³å®šï¼Œè£‚ç¼éƒ¨ä½é¿å…çƒ­èƒ€å†·ç¼©åå¤ï¼›åŠ å›ºææ–™éœ€å…¼å®¹æœ¨æçº¤ç»´ã€‚")

    # å‰¥è½/èµ·ç”²
    if pp > 0.1:
        if pp < 1:
            recs.append("å‰¥è½è½»åº¦ï¼šå°é¢ç§¯èµ·ç”²å¯å…ˆåšè¾¹ç¼˜ç‚¹å›ºä¸å±€éƒ¨å›è´´ï¼Œç°åœºè§‚å¯Ÿå…¶å‘å±•è¶‹åŠ¿ã€‚")
        elif pp < 5:
            recs.append("å‰¥è½ä¸­åº¦ï¼šå¯¹ç©ºé¼“/èµ·ç”²åŒºåŸŸè¿›è¡Œæ³¨æµ†å›è´´ï¼Œè¾¹ç•Œå¤„é‡‡ç”¨é€æ®µåŠ å›ºï¼›ä½œä¸šå‰è¿›è¡Œææ€§ä¸ç²˜ç»“è¯•éªŒã€‚")
        else:
            recs.append("å‰¥è½é‡åº¦ï¼šå¤§é¢ç§¯é¢å±‚ä¸ç¨³ï¼Œéœ€åˆ†åŒºåˆ†æ­¥å›è´´ä¸ç½‘æ ¼åŒ–ç®¡ç†ï¼Œè¿‡ç¨‹ä¸­ä¿æŒç¯å¢ƒç¨³å®šå¹¶åšå¥½æ”¯æ’‘ä¸é˜²å è½é˜²æŠ¤ã€‚")
        if "ç ‚å²©" in m:
            recs.append("ç ‚å²©æ³¨æ„ï¼šå…ˆåšåŸºä½“å«ç›/å«æ°´è¯„ä¼°ï¼Œå¿…è¦æ—¶å…ˆæœŸè„±ç›ä¸å¹²ç‡¥åå†è¡Œå›è´´åŠ å›ºã€‚")

    # è¤ªè‰²/ç²‰åŒ–
    if dp > 0.1:
        if dp < 1:
            recs.append("è¤ªè‰²è½»åº¦ï¼šåŠ å¼ºå…‰ç…§ä¸æ¸©æ¹¿ç®¡ç†ï¼Œé¿å…è§¦æ‘¸ä¸é£æ²™ç£¨èš€ï¼›å»ºç«‹é«˜ä¿çœŸå½±åƒæ¡£æ¡ˆã€‚")
        elif dp < 5:
            recs.append("è¤ªè‰²ä¸­åº¦ï¼šè¿›è¡Œé¢œæ–™å±‚ç¨³å›ºæ€§æµ‹è¯•ï¼Œé€‰æ‹©ä½å…‰æ³½ã€å¯é€†çš„è¡¨é¢ç¨³è‰²/å›ºè‰²å¤„ç†ï¼›é™å®šå‚è§‚è·ç¦»ä¸æ—¶é—´ã€‚")
        else:
            recs.append("è¤ªè‰²é‡åº¦ï¼šç»„ç»‡ææ–™å­¦è¯„ä¼°ï¼ˆé¢œæ–™çŸ¿ç‰©ä¸é»ç»“ç›¸ï¼‰ï¼Œé‡‡ç”¨æœ€å°å¹²é¢„çš„å¯é€†ç¨³è‰²ä½“ç³»å¹¶å»ºç«‹é•¿æœŸå…‰ç…§é˜ˆå€¼ç®¡ç†ã€‚")
        if "ç°æ³¥/é¢œæ–™" in m:
            recs.append("ç°æ³¥/é¢œæ–™å±‚æ³¨æ„ï¼šä¸¥æ§ç´«å¤–ä¸æŒ¥å‘æ€§æ±¡æŸ“ç‰©ï¼Œæ“ä½œä½¿ç”¨ä¸­æ€§pHæ¸…æ´ä¸ä¿æŠ¤ä½“ç³»ï¼Œé¿å…æ·±åº¦æ¸—å…¥å‹ææ–™ã€‚")

    # æ±¡æ¸/éœ‰æ–‘
    if sp > 0.1:
        if sp < 1:
            recs.append("æ±¡æ¸è½»åº¦ï¼šé‡‡ç”¨å¹²å¼/ä½æ¹¿æ¸…æ´ï¼ˆè½¯åˆ·/å¾®å¸ï¼‰å»é™¤è¡¨é¢å°˜å¢ï¼Œå…ˆåšå°æ ·è¯•éªŒã€‚")
        elif sp < 5:
            recs.append("æ±¡æ¸ä¸­åº¦ï¼šå±€éƒ¨é…åˆå‡èƒ¶æ¸…æ´ä¸æ§æ¹¿å¤„ç†ï¼Œæ¸…æ´ååšå†æ±¡æŸ“é˜²æŠ¤ã€‚")
        else:
            recs.append("æ±¡æ¸é‡åº¦ï¼šåˆ¶å®šåˆ†åŒºæ¸…æ´æ–¹æ¡ˆï¼Œé…åˆç¯å¢ƒæ²»ç†ï¼ˆè¿‡æ»¤/å¯†å°/äººæµæ§åˆ¶ï¼‰å¹¶è¯„ä¼°é¢œæ–™å±‚ç¨³å®šæ€§ã€‚")

    # ç›èš€/é£åŒ–
    if sap > 0.1:
        if sap < 1:
            recs.append("ç›èš€è½»åº¦ï¼šç›‘æµ‹ç›èŠ±ä¸ç™½åŒ–ï¼Œæ§åˆ¶æ°´æºä¸æ¹¿åº¦æ³¢åŠ¨ï¼›é¿å…ç›´æ¥æ°´æ´—é€ æˆç›è¿ç§»ã€‚")
        elif sap < 5:
            recs.append("ç›èš€ä¸­åº¦ï¼šå®æ–½æ¸©å’Œè„±ç›ï¼ˆçº¸æµ†/å‡èƒ¶ï¼‰ä¸æ°”å€™è°ƒæ§ï¼Œéšåè¿›è¡ŒåŸºä½“åŠ å›ºï¼›å¿…è¦æ—¶è¡¨é¢é˜²ç›å±éšœã€‚")
        else:
            recs.append("ç›èš€é‡åº¦ï¼šå…ˆæœŸç³»ç»Ÿè„±ç›ä¸å¹²ç‡¥ï¼Œå†åˆ†é˜¶æ®µç»“æ„ä¸è¡¨å±‚åŠ å›ºï¼›å»ºç«‹é•¿æœŸæ¸—æ°´/å«ç›ç›‘æµ‹ä½“ç³»ã€‚")
        if "æœ¨è´¨" in m:
            recs.append("æœ¨è´¨æ³¨æ„ï¼šç›èš€é€šå¸¸æ¬¡è¦ï¼Œé‡ç‚¹æ”¾åœ¨é˜²éœ‰ä¸å«æ°´ç‡æ§åˆ¶ï¼Œä¸å®œé‡‡ç”¨é«˜å«æ°´å¤„ç†ã€‚")

    # ç”Ÿç‰©é™„ç€
    if bp > 0.1:
        if bp < 1:
            recs.append("ç”Ÿç‰©è½»åº¦ï¼šå¢å¼ºé€šé£ä¸å¹²ç‡¥ï¼Œæ¶ˆé™¤ç§¯å°˜ä¸è¥å…»æºï¼Œç‰©ç†æ€§å»é™¤ä¸ºä¸»ã€‚")
        elif bp < 5:
            recs.append("ç”Ÿç‰©ä¸­åº¦ï¼šå°èŒƒå›´ä½¿ç”¨ä½æ¯’å¯é€†æ€§ç”Ÿç‰©æŠ‘åˆ¶å‰‚ï¼ˆå…ˆè¯•éªŒå†ä½¿ç”¨ï¼‰ï¼Œå¹¶æŒç»­æ§æ¹¿æ§å…‰ã€‚")
        else:
            recs.append("ç”Ÿç‰©é‡åº¦ï¼šåˆ¶å®šç»¼åˆæ²»ç†ï¼ˆæ§æ¹¿ã€æ§å…‰ã€å®šæœŸç»´æŠ¤ä¸è¿‡æ»¤ï¼‰ï¼Œå¿…è¦æ—¶åˆ†æ‰¹æ¬¡åŒ–å­¦æŠ‘åˆ¶å¹¶è¯„ä¼°å¯¹é¢œæ–™å±‚å½±å“ã€‚")
        if "æœ¨è´¨" in m:
            recs.append("æœ¨è´¨æ³¨æ„ï¼šä¼˜å…ˆé˜²éœ‰é˜²è™«ï¼Œè€ƒè™‘ç†è’¸/å±€éƒ¨æŠ—èŒä¸é˜²è™«å¤„ç½®ï¼Œå¹¶ä¸¥æ§å«æ°´ç‡ã€‚")

    # æ€»ä½“ç­–ç•¥
    if overall_severity < 5:
        recs.append("æ€»ä½“ï¼šé—®é¢˜è½»å¾®ï¼Œçº³å…¥å¸¸è§„å·¡æ£€ä¸å½±åƒæ¡£æ¡ˆç®¡ç†ï¼ŒåŠå¹´/ä¸€å¹´å¤æŸ¥ã€‚")
    elif overall_severity < 20:
        recs.append("æ€»ä½“ï¼šä¸­åº¦ç—…å®³ï¼Œå»ºè®®åˆ¶å®šåˆ†åŒºæ²»ç†è®¡åˆ’ä¸ä¼˜å…ˆçº§ï¼Œå…ˆåšæ ·åŒºè¯•éªŒåå†å…¨é¢å±•å¼€ã€‚")
    else:
        recs.append("æ€»ä½“ï¼šé‡åº¦ç—…å®³ï¼Œå°½å¿«ç»„ç»‡è·¨ä¸“ä¸šå›¢é˜Ÿï¼ˆç»“æ„ã€ææ–™ã€ç¯å¢ƒï¼‰è”åˆè¯„ä¼°ä¸å¤„ç½®ï¼Œè®¾ç½®é•¿æœŸç›‘æµ‹ã€‚")

    # é™„ï¼šæè´¨ä¸“ç”¨æç¤º
    recs += MATERIAL_SUGGESTIONS.get(m, [])
    return recs

# ---------------------------
# Image preprocessing & detection functions (classical CV baseline)
# ---------------------------

def preprocess_image(image_bgr, target_max_dim=1600):
    """Resize while keeping aspect ratio for reasonable processing time."""
    h, w = image_bgr.shape[:2]
    scale = 1.0
    max_dim = max(h, w)
    if max_dim > target_max_dim:
        scale = target_max_dim / max_dim
        image_bgr = cv2.resize(image_bgr, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)
    return image_bgr, scale

def detect_cracks(gray):
    """Detect fine elongated structures (baseline): morphological thinning + contour filtering."""
    # enhance contrast
    gray_eq = cv2.equalizeHist(gray)
    # use Scharr or Sobel to get strong gradients
    grad_x = cv2.Sobel(gray_eq, cv2.CV_16S, 1, 0, ksize=3)
    grad_y = cv2.Sobel(gray_eq, cv2.CV_16S, 0, 1, ksize=3)
    grad = cv2.convertScaleAbs(cv2.addWeighted(cv2.convertScaleAbs(grad_x), 0.5, cv2.convertScaleAbs(grad_y), 0.5, 0))
    # binary threshold + morphological closing to join thin lines
    _, th = cv2.threshold(grad, 30, 255, cv2.THRESH_BINARY)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=1)
    # find contours and filter elongated
    cnts = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = cnts[0] if len(cnts) == 2 else cnts[1]
    boxes = []
    mask = np.zeros_like(th)
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        area = w*h
        if area < 80: 
            continue
        # elongated or thin filter
        if (w > 4*h) or (h > 4*w) or (area < 200 and max(w,h) > 40):
            boxes.append((x,y,w,h))
            cv2.drawContours(mask, [c], -1, 255, -1)
    return boxes, mask

def detect_peeling(hsv):
    """Low saturation patches (å‰¥è½/ç°ç™½æ–‘å—)"""
    h,s,v = cv2.split(hsv)
    # threshold low saturation but not pure dark
    low_sat = cv2.inRange(hsv, (0,0,40), (180,70,255))
    # remove tiny speckles
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7))
    low_sat = cv2.morphologyEx(low_sat, cv2.MORPH_OPEN, kernel, iterations=1)
    cnts = cv2.findContours(low_sat, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = cnts[0] if len(cnts) == 2 else cnts[1]
    boxes = []
    mask = np.zeros_like(low_sat)
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        if w*h < 400: 
            continue
        boxes.append((x,y,w,h))
        cv2.drawContours(mask, [c], -1, 255, -1)
    return boxes, mask

def detect_discoloration(hsv):
    """Overly bright or faded regions: high V with low to mid saturation"""
    lower = np.array([0,0,180])
    upper = np.array([180,90,255])
    light_mask = cv2.inRange(hsv, lower, upper)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))
    light_mask = cv2.morphologyEx(light_mask, cv2.MORPH_OPEN, kernel, iterations=1)
    cnts = cv2.findContours(light_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = cnts[0] if len(cnts) == 2 else cnts[1]
    boxes = []
    mask = np.zeros_like(light_mask)
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        if w*h < 300: 
            continue
        boxes.append((x,y,w,h))
        cv2.drawContours(mask, [c], -1, 255, -1)
    return boxes, mask

# ---------------------------
# Material classification (heuristic + optional ONNX)
# ---------------------------
def classify_material_heuristic(image_bgr):
    """Return (material_name, confidence_0_1, details_dict) based on simple cues.
    Heuristic cues:
    - Brown/orange ratio (wood tendency)
    - Orientation coherence (wood grain)
    - High-bright low-sat salts (stone tendency)
    """
    img_small = cv2.resize(image_bgr, (min(640, image_bgr.shape[1]), min(640, image_bgr.shape[0])), interpolation=cv2.INTER_AREA)
    hsv = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)
    # brown-ish mask (wood): hue 10-30, moderate saturation/value
    brown = cv2.inRange(hsv, (10, 40, 40), (30, 255, 220))
    brown_ratio = float(np.mean(brown > 0))

    # salt-like (stone efflorescence): very bright low S
    salt_like = cv2.inRange(hsv, (0, 0, 220), (180, 40, 255))
    salt_ratio = float(np.mean(salt_like > 0))

    # orientation coherence via gradients
    gray = cv2.cvtColor(img_small, cv2.COLOR_BGR2GRAY)
    gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)
    gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)
    mag, ang = cv2.cartToPolar(gx, gy, angleInDegrees=True)
    # compute histogram concentration around main orientation
    ang_mask = mag > (np.percentile(mag, 75))
    main_orient = np.median(ang[ang_mask]) if np.any(ang_mask) else 0.0
    concentr = float(np.mean(np.abs(((ang - main_orient + 90) % 180) - 90) < 10))

    # crude decision
    wood_score = 0.55 * brown_ratio + 0.35 * concentr + 0.10 * (1.0 - salt_ratio)
    stone_score = 0.60 * (1.0 - brown_ratio) + 0.25 * (1.0 - concentr) + 0.15 * salt_ratio

    if wood_score > stone_score:
        name = "æœ¨è´¨åŸºåº•ï¼ˆæœ¨æ¿ï¼‰"
        conf = min(1.0, max(0.0, (wood_score - stone_score) * 2.0))
    else:
        # choose between known stone presets by default to "æœªæŒ‡å®š" or closest
        name = "å¤§è¶³çŸ³åˆ»ï¼ˆç ‚å²©ï¼‰"
        conf = min(1.0, max(0.0, (stone_score - wood_score) * 2.0))

    details = {
        'brown_ratio': round(brown_ratio, 4),
        'salt_ratio': round(salt_ratio, 4),
        'orientation_concentration': round(concentr, 4)
    }
    return name, conf, details

def run_material_model(image_bgr, model_path, providers=None, class_names=None):
    if ort is None:
        raise RuntimeError("æœªå®‰è£… onnxruntimeï¼Œè¯·å…ˆå®‰è£…ï¼špip install onnxruntime")
    session = ort.InferenceSession(model_path, providers=providers or ["CPUExecutionProvider"])
    # preprocess to square 224
    target = 224
    img = cv2.resize(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB), (target, target), interpolation=cv2.INTER_AREA)
    inp = img.astype(np.float32) / 255.0
    inp = np.transpose(inp, (2,0,1))[None, ...]
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name
    out = session.run([output_name], {input_name: inp})[0]
    # softmax
    if out.ndim == 2 and out.shape[0] == 1:
        logits = out[0]
    elif out.ndim == 1:
        logits = out
    else:
        raise ValueError("æè´¨æ¨¡å‹è¾“å‡ºå½¢çŠ¶ä¸æ”¯æŒï¼š" + str(out.shape))
    exps = np.exp(logits - np.max(logits))
    probs = exps / np.sum(exps)
    if class_names is None:
        class_names = [
            "æœªæŒ‡å®š",
            "å¤§è¶³çŸ³åˆ»ï¼ˆç ‚å²©ï¼‰",
            "äº‘å†ˆçŸ³çªŸï¼ˆç ‚å²©å¤¹æ³¥å²©ï¼‰",
            "æ•¦ç…Œè«é«˜çªŸï¼ˆç°æ³¥/é¢œæ–™å±‚ï¼‰",
            "æœ¨è´¨åŸºåº•ï¼ˆæœ¨æ¿ï¼‰"
        ]
    idx = int(np.argmax(probs))
    return class_names[idx], float(np.max(probs)), dict(zip(class_names[:len(probs)], [float(p) for p in probs]))

# é¢å¤–ç±»åˆ«ï¼ˆæ±¡æ¸/éœ‰æ–‘ã€ç›èš€/é£åŒ–ã€ç”Ÿç‰©é™„ç€ï¼‰
def detect_stain_mold(hsv):
    """Dark colored spots or stains: low V with moderate-high S"""
    lower = np.array([0, 40, 0])
    upper = np.array([180, 255, 90])
    mask = cv2.inRange(hsv, lower, upper)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = cnts[0] if len(cnts) == 2 else cnts[1]
    boxes = []
    mask_out = np.zeros_like(mask)
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        if w*h < 300:
            continue
        boxes.append((x,y,w,h))
        cv2.drawContours(mask_out, [c], -1, 255, -1)
    return boxes, mask_out

def detect_salt_weathering(hsv):
    """Efflorescence/whitish salt: very high V, very low S"""
    lower = np.array([0, 0, 200])
    upper = np.array([180, 35, 255])
    mask = cv2.inRange(hsv, lower, upper)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = cnts[0] if len(cnts) == 2 else cnts[1]
    boxes = []
    mask_out = np.zeros_like(mask)
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        if w*h < 400:
            continue
        boxes.append((x,y,w,h))
        cv2.drawContours(mask_out, [c], -1, 255, -1)
    return boxes, mask_out

def detect_bio_growth(hsv):
    """Biological growth (moss/algae): greenish hue, high S"""
    lower = np.array([35, 60, 40])
    upper = np.array([85, 255, 255])
    mask = cv2.inRange(hsv, lower, upper)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = cnts[0] if len(cnts) == 2 else cnts[1]
    boxes = []
    mask_out = np.zeros_like(mask)
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        if w*h < 300:
            continue
        boxes.append((x,y,w,h))
        cv2.drawContours(mask_out, [c], -1, 255, -1)
    return boxes, mask_out

# ---------------------------
# Deep model inference (ONNX)
# ---------------------------
def run_segmentation_model(image_bgr, model_path, input_size=512, class_ids=None, providers=None):
    """Run ONNX segmentation model and return masks dict.

    Assumptions:
    - Input: RGB float32 0-1, NCHW (1,C,H,W). We will transpose accordingly.
    - Output: either NCHW (1,C,H,W) or NHWC (1,H,W,C) or HW (single channel) or HxW (after squeeze).
    - Class mapping provided via class_ids: {'bg':0,'crack':1,'peel':2,'disc':3}.
    """
    if ort is None:
        raise RuntimeError("æœªå®‰è£… onnxruntimeï¼Œè¯·å…ˆå®‰è£…ï¼špip install onnxruntime")

    if class_ids is None:
        class_ids = {'bg': 0, 'crack': 1, 'peel': 2, 'disc': 3, 'stain': 4, 'salt': 5, 'bio': 6}

    # Prepare session (cached)
    session = get_onnx_session_cached(model_path, providers=providers or ["CPUExecutionProvider"])

    # Preprocess: BGR->RGB, resize square, normalize to [0,1]
    h0, w0 = image_bgr.shape[:2]
    target = int(input_size)
    img_resized = cv2.resize(image_bgr, (target, target), interpolation=cv2.INTER_AREA)
    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
    inp = img_rgb.astype(np.float32) / 255.0
    # to NCHW
    inp = np.transpose(inp, (2,0,1))[None, ...]  # (1,3,H,W)

    # IO names
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name

    out = session.run([output_name], {input_name: inp})[0]
    # Postprocess to class map HxW
    class_map = None
    if out.ndim == 4:
        # (N,C,H,W) or (N,H,W,C)
        if out.shape[1] <= 6 and out.shape[0] == 1:  # likely NCHW classes small
            class_map = np.argmax(out[0], axis=0)
        elif out.shape[-1] <= 6 and out.shape[0] == 1:  # NHWC
            class_map = np.argmax(out[0], axis=-1)
        else:
            # fallback: take channel-argmax in the dimension that matches classes<=20
            if out.shape[1] < out.shape[-1]:
                class_map = np.argmax(out[0], axis=0)
            else:
                class_map = np.argmax(out[0], axis=-1)
    elif out.ndim == 3:
        # (C,H,W) or (H,W,C)
        if out.shape[0] <= 6:
            class_map = np.argmax(out, axis=0)
        elif out.shape[-1] <= 6:
            class_map = np.argmax(out, axis=-1)
        else:
            raise ValueError("æ— æ³•è§£ææ¨¡å‹è¾“å‡ºå½¢çŠ¶ï¼š" + str(out.shape))
    elif out.ndim == 2:
        # binary logits/mask -> treat >0.5 as class 'crack' by default
        class_map = (out > 0.5).astype(np.uint8) * class_ids.get('crack', 1)
    else:
        raise ValueError("æœªæ”¯æŒçš„æ¨¡å‹è¾“å‡ºç»´åº¦ï¼š" + str(out.shape))

    # Resize back to original size
    class_map = cv2.resize(class_map.astype(np.int32), (w0, h0), interpolation=cv2.INTER_NEAREST)

    crack_id = int(class_ids.get('crack', 1))
    peel_id = int(class_ids.get('peel', 2))
    disc_id = int(class_ids.get('disc', 3))
    stain_id = class_ids.get('stain', None)
    salt_id = class_ids.get('salt', None)
    bio_id = class_ids.get('bio', None)

    masks = {
        'crack': (class_map == crack_id).astype(np.uint8) * 255,
        'peel': (class_map == peel_id).astype(np.uint8) * 255,
        'disc': (class_map == disc_id).astype(np.uint8) * 255
    }
    if stain_id is not None:
        masks['stain'] = (class_map == int(stain_id)).astype(np.uint8) * 255
    if salt_id is not None:
        masks['salt'] = (class_map == int(salt_id)).astype(np.uint8) * 255
    if bio_id is not None:
        masks['bio'] = (class_map == int(bio_id)).astype(np.uint8) * 255
    return masks

# ---------------------------
# UI and main logic
# ---------------------------
st.markdown("<h1 style='text-align:center;color:#8B4513;'>ğŸ›ï¸ çŸ³çªŸå¯ºå£ç”»ç—…å®³AIè¯†åˆ«å·¥å…·ï¼ˆå‡çº§ç‰ˆï¼‰</h1>", unsafe_allow_html=True)
st.write("æœ¬å·¥å…·ä¸ºç§‘ç ”åŸå‹ï¼šé‡‡ç”¨ä¼ ç»Ÿå›¾åƒå¤„ç†æ–¹æ³•ä½œä¸ºåŸºçº¿ï¼Œå¹¶æä¾›æ·±åº¦æ¨¡å‹æ¥å…¥ç‚¹ï¼›è¾“å‡ºç—…å®³æ£€æµ‹ã€ä¸¥é‡åº¦è¯„åˆ†ã€æè´¨è‡ªé€‚åº”å»ºè®®ä¸å«æ ‡æ³¨å›¾åƒçš„ PDFã€‚")

# Sidebar controls
st.sidebar.markdown("### é…ç½®ä¸æè´¨é€‰æ‹©")
material = st.sidebar.selectbox("é€‰æ‹©å£ç”»æè´¨ï¼ˆå½±å“è¯„åˆ†ä¸å»ºè®®ï¼‰", MATERIAL_OPTIONS)
auto_material = st.sidebar.checkbox("è‡ªåŠ¨è¯†åˆ«æè´¨ï¼ˆè¯•éªŒæ€§ï¼‰", value=False)
mat_model_path = None
if auto_material:
    st.sidebar.markdown("- å¯é€‰ï¼šæä¾›æè´¨åˆ†ç±»ONNXæ¨¡å‹è·¯å¾„ï¼ˆè‹¥ç•™ç©ºåˆ™ä½¿ç”¨å¯å‘å¼è¯†åˆ«ï¼‰")
    mat_model_path = st.sidebar.text_input("æè´¨æ¨¡å‹è·¯å¾„ï¼ˆ.onnxï¼Œå¯é€‰ï¼‰", "")
use_deep = st.sidebar.checkbox("ä½¿ç”¨æ·±åº¦åˆ†å‰²æ¨¡å‹ï¼ˆONNXï¼‰", value=False)
model_path = None
model_input_size = 512
# æ€§èƒ½/é€Ÿåº¦è®¾ç½®
st.sidebar.markdown("### æ€§èƒ½/é€Ÿåº¦è®¾ç½®")
max_dim_setting = st.sidebar.slider("æœ€å¤§å¤„ç†åˆ†è¾¨ç‡ï¼ˆåƒç´ ï¼‰", 512, 2048, 1280, 64)
icp_threshold = st.sidebar.slider("3D ICP è·ç¦»é˜ˆå€¼ (m)", 0.002, 0.05, 0.02, 0.002)
class_id_bg = 0
class_id_crack = 1
class_id_peel = 2
class_id_disc = 3
class_id_stain = 4
class_id_salt = 5
class_id_bio = 6
if use_deep:
    model_path = st.sidebar.text_input("æ¨¡å‹è·¯å¾„ï¼ˆ.onnxï¼‰", "")
    model_input_size = st.sidebar.selectbox("æ¨¡å‹è¾“å…¥å°ºå¯¸ï¼ˆæ–¹å½¢ï¼‰", [256, 320, 384, 512, 640, 768, 1024], index=3)
    st.sidebar.markdown("#### ç±»åˆ«IDæ˜ å°„ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰")
    col1, col2 = st.sidebar.columns(2)
    with col1:
        class_id_bg = st.number_input("èƒŒæ™¯ID", value=0, step=1)
        class_id_crack = st.number_input("è£‚ç¼ID", value=1, step=1)
        class_id_stain = st.number_input("æ±¡æ¸/éœ‰æ–‘ID", value=4, step=1)
    with col2:
        class_id_peel = st.number_input("å‰¥è½ID", value=2, step=1)
        class_id_disc = st.number_input("è¤ªè‰²ID", value=3, step=1)
        class_id_salt = st.number_input("ç›èš€/é£åŒ–ID", value=5, step=1)
    class_id_bio = st.sidebar.number_input("ç”Ÿç‰©é™„ç€ID", value=6, step=1)

# Display controls (å»æ‚åŒ–)
st.sidebar.markdown("### æ˜¾ç¤ºè®¾ç½®ï¼ˆå‡å°‘å¹²æ‰°ï¼‰")
display_mode = st.sidebar.selectbox(
    "æ˜¾ç¤ºæ–¹å¼",
    ["ä»…æ©è†œ", "ä»…è¾¹æ¡†", "è¾¹æ¡†+æ©è†œ"],
    index=0
)
min_area = st.sidebar.slider("æœ€å°ç›®æ ‡é¢ç§¯ï¼ˆåƒç´ ï¼‰", 0, 5000, 400, step=50)
show_crack = st.sidebar.checkbox("æ˜¾ç¤ºï¼šè£‚ç¼", True)
show_peel = st.sidebar.checkbox("æ˜¾ç¤ºï¼šå‰¥è½", True)
show_disc = st.sidebar.checkbox("æ˜¾ç¤ºï¼šè¤ªè‰²", True)
show_stain = st.sidebar.checkbox("æ˜¾ç¤ºï¼šæ±¡æ¸/éœ‰æ–‘", True)
show_salt = st.sidebar.checkbox("æ˜¾ç¤ºï¼šç›èš€/é£åŒ–", True)
show_bio = st.sidebar.checkbox("æ˜¾ç¤ºï¼šç”Ÿç‰©é™„ç€", True)
show_labels = st.sidebar.checkbox("åœ¨å›¾ä¸Šæ ‡æ³¨ç±»åˆ«ç®€å†™", True)
label_lang = st.sidebar.selectbox("æ ‡ç­¾æ ·å¼", ["ç®€å†™(EN)", "ä¸­æ–‡"], index=0)

# å®å°ºæ ‡å®šï¼ˆåƒç´ -æ¯«ç±³æ¢ç®—ï¼‰
st.sidebar.markdown("### å®å°ºæ ‡å®šï¼ˆå•ä½è½¬æ¢ï¼‰")
if "ppmm" not in st.session_state:
    st.session_state["ppmm"] = None  # pixels per millimeter
scale_mode = st.sidebar.selectbox("æ ‡å®šæ–¹å¼", ["æœªæ ‡å®š", "ç›´æ¥è¾“å…¥åƒç´ /æ¯«ç±³", "å‚è€ƒç‰©æ ‡å®šï¼ˆè¾“å…¥åƒç´ é•¿åº¦ä¸å®é•¿mmï¼‰"], index=0)
ppmm_direct = None
if scale_mode == "ç›´æ¥è¾“å…¥åƒç´ /æ¯«ç±³":
    ppmm_direct = st.sidebar.number_input("åƒç´ /æ¯«ç±³ (pixels per mm)", min_value=0.0, value=float(st.session_state["ppmm"]) if st.session_state["ppmm"] else 0.0, step=0.01)
    if ppmm_direct > 0:
        st.session_state["ppmm"] = ppmm_direct
elif scale_mode == "å‚è€ƒç‰©æ ‡å®šï¼ˆè¾“å…¥åƒç´ é•¿åº¦ä¸å®é•¿mmï¼‰":
    ref_px = st.sidebar.number_input("å‚è€ƒç‰©åœ¨å›¾ä¸­çš„åƒç´ é•¿åº¦", min_value=0.0, value=0.0, step=1.0)
    ref_mm = st.sidebar.number_input("å‚è€ƒç‰©å®é™…é•¿åº¦ï¼ˆmmï¼‰", min_value=0.0, value=0.0, step=0.1)
    if ref_px > 0 and ref_mm > 0:
        st.session_state["ppmm"] = ref_px / ref_mm
_ppmm_val = st.session_state["ppmm"]
if _ppmm_val:
    st.sidebar.caption(f"å½“å‰æ ‡å®šï¼š{_ppmm_val:.3f} åƒç´ /æ¯«ç±³")
else:
    st.sidebar.caption("å½“å‰æ ‡å®šï¼šæœªæ ‡å®š")

# Upload (æ”¯æŒå†å²å¯¹æ¯”ï¼šå…è®¸ä¸Šä¼ æ—§å›¾åƒ)
# é¡µé¢è£…é¥°ï¼šåŠ¨æ€èƒŒæ™¯ä¸æ ¡å¾½è§’æ ‡
try:
    bg_imgs = get_background_images_b64()
    inject_dynamic_background(bg_imgs, interval_ms=10000)
    logo_data = get_logo_b64()
    inject_brand_badge(logo_data)
except Exception:
    pass
tabs = st.tabs(["äºŒç»´å£ç”»è¯Šæ–­", "ä¸‰ç»´çŸ³çªŸç›‘æµ‹ï¼ˆåŸºç¡€ç‰ˆï¼‰", "æ–‡çŒ®èµ„æ–™è¯†åˆ«ï¼ˆOCRï¼‰", "å¤šæ¨¡æ€èåˆè¯Šæ–­"])

with tabs[0]:
    st.markdown("#### 1) ä¸Šä¼ å›¾åƒï¼ˆå¯ä¸Šä¼  1-2 å¼ ç”¨äºæ—¶é—´å¯¹æ¯”ï¼‰")
uploaded = st.file_uploader("ä¸Šä¼ å½“å‰å›¾åƒï¼ˆå¿…å¡«ï¼‰", type=['jpg','jpeg','png'])
uploaded_prev = st.file_uploader("ä¸Šä¼ å†å²å›¾åƒï¼ˆå¯é€‰ï¼Œç”¨äºå¯¹æ¯”ï¼‰ï¼Œè‹¥æœ‰åˆ™ä¸ºåŒä¸€å£ç”»çš„æ—©æœŸç…§ç‰‡", type=['jpg','jpeg','png'])

analyze_btn = st.button("å¼€å§‹åˆ†æ")

if analyze_btn and uploaded is None:
    st.error("è¯·è‡³å°‘ä¸Šä¼ å½“å‰å›¾åƒä»¥è¿›è¡Œåˆ†æã€‚")

if uploaded is not None and analyze_btn:
    # read images
    file_bytes = np.asarray(bytearray(uploaded.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
    if img is None:
        st.error("æ— æ³•è¯»å–å›¾åƒï¼Œè¯·ç¡®è®¤æ ¼å¼æ­£ç¡®ã€‚")
    else:
        img_proc, scale = preprocess_image(img.copy(), target_max_dim=int(max_dim_setting))
        img_rgb = cv2.cvtColor(img_proc, cv2.COLOR_BGR2RGB)
        st.subheader("åŸå§‹å›¾åƒï¼ˆå·²ç¼©æ”¾ä»¥ä¾¿å¤„ç†ï¼‰")
        # Auto material detection
        detected_material = None
        detected_conf = None
        detected_details = None
        if auto_material:
            try:
                if mat_model_path:
                    detected_material, detected_conf, mat_probs = run_material_model(img_proc, mat_model_path)
                    detected_details = {"probs": mat_probs}
                else:
                    detected_material, detected_conf, detected_details = classify_material_heuristic(img_proc)
                st.info(f"è‡ªåŠ¨è¯†åˆ«æè´¨ï¼š{detected_material}ï¼ˆç½®ä¿¡åº¦ {detected_conf:.2f}ï¼‰")
                apply_mat = st.toggle("å°†è¯†åˆ«ç»“æœåº”ç”¨åˆ°è¯„åˆ†/å»ºè®®", value=True)
                if apply_mat:
                    material = detected_material
            except Exception as e:
                st.warning(f"è‡ªåŠ¨æè´¨è¯†åˆ«å¤±è´¥ï¼š{e}")

        st.image(img_rgb, width='stretch')

        # OCR è¯†åˆ«ï¼ˆå¯é€‰ï¼‰
        st.markdown("### ğŸ”¤ æ–‡å­—è¯†åˆ«ï¼ˆOCRï¼‰")
        if RapidOCR is None:
            st.info("æœªå®‰è£… rapidocr-onnxruntimeï¼Œå¦‚éœ€OCRï¼špip install rapidocr-onnxruntime")
        else:
            if st.toggle("å¯ç”¨OCRè¯†åˆ«ï¼ˆå®éªŒæ€§ï¼‰", value=False):
                ocr = get_rapidocr_cached()
                if ocr is None:
                    st.warning("OCR åˆå§‹åŒ–å¤±è´¥ã€‚")
                else:
                    with st.spinner("OCRè¯†åˆ«ä¸­â€¦"):
                        res, elapse = ocr(img_rgb)
                    # å±•ç¤ºç»“æœå’Œå¯ä¸‹è½½TXT
                    ocr_lines = []
                    if res:
                        for box, text, score in res:
                            ocr_lines.append(f"{text}\t{score:.3f}")
                        st.success(f"è¯†åˆ«åˆ° {len(ocr_lines)} è¡Œæ–‡æœ¬ã€‚")
                        st.code("\n".join(ocr_lines))
                        st.download_button("ä¸‹è½½OCRç»“æœï¼ˆtxtï¼‰", data=("\n".join(ocr_lines)).encode("utf-8"), file_name="ocr_result.txt", mime="text/plain")
                    else:
                        st.info("æœªè¯†åˆ«åˆ°æ˜æ˜¾æ–‡æœ¬åŒºåŸŸã€‚")

        # Optionally run deep model
        deep_masks = None
        if use_deep and model_path:
            try:
                deep_masks = run_segmentation_model(
                    img_proc,
                    model_path=model_path,
                    input_size=int(model_input_size),
                    class_ids={
                        'bg': int(class_id_bg),
                        'crack': int(class_id_crack),
                        'peel': int(class_id_peel),
                        'disc': int(class_id_disc),
                        'stain': int(class_id_stain),
                        'salt': int(class_id_salt),
                        'bio': int(class_id_bio)
                    },
                    providers=["CPUExecutionProvider"]
                )
                st.success("æ·±åº¦åˆ†å‰²å·²å¯ç”¨ï¼šç»“æœå°†æ›¿æ¢ä¼ ç»ŸCVæ©è†œã€‚")
            except Exception as e:
                st.exception(e)
                st.error("æ·±åº¦æ¨¡å‹æ¨ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„ã€ç±»åˆ«IDä¸è¾“å…¥å°ºå¯¸æ˜¯å¦åŒ¹é…ã€‚")
                deep_masks = None

        # Baseline CV detections
        gray = cv2.cvtColor(img_proc, cv2.COLOR_BGR2GRAY)
        hsv = cv2.cvtColor(img_proc, cv2.COLOR_BGR2HSV)
        boxes_crack, mask_crack = detect_cracks(gray)
        boxes_peel, mask_peel = detect_peeling(hsv)
        boxes_disc, mask_disc = detect_discoloration(hsv)
        boxes_stain, mask_stain = detect_stain_mold(hsv)
        boxes_salt, mask_salt = detect_salt_weathering(hsv)
        boxes_bio, mask_bio = detect_bio_growth(hsv)

        # If deep_masks provided, prefer it
        if deep_masks:
            # expected keys 'crack','peel','disc' -> binary masks same size as img_proc
            if 'crack' in deep_masks:
                mask_crack = deep_masks['crack']
            if 'peel' in deep_masks:
                mask_peel = deep_masks['peel']
            if 'disc' in deep_masks:
                mask_disc = deep_masks['disc']
            if 'stain' in deep_masks:
                mask_stain = deep_masks['stain']
            if 'salt' in deep_masks:
                mask_salt = deep_masks['salt']
            if 'bio' in deep_masks:
                mask_bio = deep_masks['bio']

        # Annotate image for visualization
        annotated = img_rgb.copy()
        # Helper to draw boxes with filters
        def draw_boxes(boxes, color, visible, tag_text):
            if not visible or display_mode == "ä»…æ©è†œ":
                return
            for (x,y,w,h) in boxes:
                if w*h < min_area:
                    continue
                cv2.rectangle(annotated, (x,y), (x+w, y+h), color, 2)
                if show_labels:
                    # draw a small label background for readability
                    tx = x
                    ty = max(0, y-8)
                    text = tag_text
                    (tw, th), bl = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.45, 1)
                    cv2.rectangle(annotated, (tx, ty-th-4), (tx+tw+4, ty+2), (0,0,0), -1)
                    cv2.putText(annotated, text, (tx+2, ty-2), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 1, cv2.LINE_AA)

        # Draw per category (no Chinese labels on image toé¿å…é—®å·)
        # label text mapping
        if label_lang == "ä¸­æ–‡":
            # OpenCV ä¸æ”¯æŒä¸­æ–‡å­—ä½“ï¼Œå¯èƒ½æ˜¾ç¤ºé—®å·ï¼›è‹¥å‡ºç°ï¼Œè¯·åˆ‡æ¢åˆ°â€œç®€å†™(EN)â€
            crack_t, peel_t, disc_t, stain_t, salt_t, bio_t = "è£‚", "å‰¥", "è¤ª", "æ±¡", "ç›", "ç”Ÿ"
        else:
            crack_t, peel_t, disc_t, stain_t, salt_t, bio_t = "CR", "PL", "DC", "ST", "SA", "BIO"

        draw_boxes(boxes_crack, (255,0,0), show_crack, crack_t)
        draw_boxes(boxes_peel, (0,255,0), show_peel, peel_t)
        draw_boxes(boxes_disc, (0,0,255), show_disc, disc_t)
        draw_boxes(boxes_stain, (255,255,0), show_stain, stain_t)
        draw_boxes(boxes_salt, (0,255,255), show_salt, salt_t)
        draw_boxes(boxes_bio, (255,0,255), show_bio, bio_t)

        # Also overlay masks semi-transparently to show extent
        def overlay_mask(base_rgb, mask, color_rgb, alpha=0.35):
            overlay = base_rgb.copy()
            mask_bool = mask > 0
            overlay[mask_bool] = (overlay[mask_bool] * (1-alpha) + np.array(color_rgb) * alpha).astype(np.uint8)
            return overlay

        if display_mode in ("ä»…æ©è†œ", "è¾¹æ¡†+æ©è†œ"):
            if show_crack:
                annotated = overlay_mask(annotated, mask_crack, (255,0,0), alpha=0.25)
            if show_peel:
                annotated = overlay_mask(annotated, mask_peel, (0,255,0), alpha=0.18)
            if show_disc:
                annotated = overlay_mask(annotated, mask_disc, (0,0,255), alpha=0.18)
            if show_stain:
                annotated = overlay_mask(annotated, mask_stain, (255,255,0), alpha=0.20)
            if show_salt:
                annotated = overlay_mask(annotated, mask_salt, (0,255,255), alpha=0.18)
            if show_bio:
                annotated = overlay_mask(annotated, mask_bio, (255,0,255), alpha=0.20)

        st.subheader("åˆ†æç»“æœï¼ˆå¸¦æ ‡æ³¨ï¼‰")
        st.image(annotated, width='stretch')

        # Legend (å›¾ä¾‹) for colors
        legend_html = """
        <div style='display:flex;flex-wrap:wrap;gap:12px;margin:6px 0 10px 0;'>
          <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#ff0000;'></span><span>è£‚ç¼</span></div>
          <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#00cc00;'></span><span>å‰¥è½</span></div>
          <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#0000ff;'></span><span>è¤ªè‰²</span></div>
          <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#ffff00;'></span><span>æ±¡æ¸/éœ‰æ–‘</span></div>
          <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#00ffff;'></span><span>ç›èš€/é£åŒ–</span></div>
          <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#ff00ff;'></span><span>ç”Ÿç‰©é™„ç€</span></div>
        </div>
        """
        st.markdown(legend_html, unsafe_allow_html=True)
        # è‰²å½©å¤åŸï¼ˆåŸºç¡€ï¼‰
        render_color_restore_ui(img_rgb, default_open=False, key_suffix="color1")

        # ---------------------
        # Quantification & scoring
        # ---------------------
        h,w = gray.shape
        total_pixels = h*w
        crack_area = int(np.sum(mask_crack>0))
        peel_area = int(np.sum(mask_peel>0))
        disc_area = int(np.sum(mask_disc>0))
        stain_area = int(np.sum(mask_stain>0))
        salt_area = int(np.sum(mask_salt>0))
        bio_area = int(np.sum(mask_bio>0))

        crack_pct = crack_area / total_pixels * 100
        peel_pct = peel_area / total_pixels * 100
        disc_pct = disc_area / total_pixels * 100
        stain_pct = stain_area / total_pixels * 100
        salt_pct = salt_area / total_pixels * 100
        bio_pct = bio_area / total_pixels * 100

        # severity score: weighted sum (0-100)
        weights = MATERIAL_WEIGHTS.get(material, MATERIAL_WEIGHTS["æœªæŒ‡å®š"])
        # normalize each by an empirical factor per category
        score = (
            weights.get('crack',1.0) * crack_pct * 1.8 +
            weights.get('peel',1.0) * peel_pct * 1.2 +
            weights.get('disc',1.0) * disc_pct * 1.5 +
            weights.get('stain',1.0) * stain_pct * 0.9 +
            weights.get('salt',1.0) * salt_pct * 1.6 +
            weights.get('bio',1.0) * bio_pct * 1.1
        )
        # map to 0-100
        severity = min(round(score,1), 100.0)

        st.markdown("### ğŸ“‹ é‡åŒ–ç»“æœ")
        st.write(f"- è£‚ç¼è¦†ç›–é¢ç§¯ï¼š{crack_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {crack_pct:.3f}%")
        st.write(f"- å‰¥è½è¦†ç›–é¢ç§¯ï¼š{peel_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {peel_pct:.3f}%")
        st.write(f"- è¤ªè‰²è¦†ç›–é¢ç§¯ï¼š{disc_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {disc_pct:.3f}%")
        st.write(f"- æ±¡æ¸/éœ‰æ–‘è¦†ç›–é¢ç§¯ï¼š{stain_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {stain_pct:.3f}%")
        st.write(f"- ç›èš€/é£åŒ–è¦†ç›–é¢ç§¯ï¼š{salt_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {salt_pct:.3f}%")
        st.write(f"- ç”Ÿç‰©é™„ç€è¦†ç›–é¢ç§¯ï¼š{bio_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {bio_pct:.3f}%")
        st.write(f"- æè´¨ï¼š**{material}**ï¼ˆç”¨äºè°ƒæ•´è¯„åˆ†ä¸å»ºè®®ï¼‰")
        st.metric("æ•´ä½“ç—…å®³ä¸¥é‡åº¦ï¼ˆ0-100ï¼‰", f"{severity}")

        # severity label
        if severity < 5:
            lvl = "è½»å¾®"
        elif severity < 20:
            lvl = "ä¸­ç­‰"
        else:
            lvl = "ä¸¥é‡"
        st.write(f"åˆ¤æ–­ç­‰çº§ï¼š**{lvl}**")

        # ---------------------
        # ç»†åŒ–ç—…ç†æŒ‡æ ‡ï¼ˆè¿é€šåŸŸ/å½¢æ€/æ–¹å‘ï¼‰
        # ---------------------
        def extract_components(mask, min_area_px=min_area):
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats((mask>0).astype(np.uint8), connectivity=8)
            rows = []
            for i in range(1, num_labels):
                area = int(stats[i, cv2.CC_STAT_AREA])
                if area < min_area_px:
                    continue
                x = int(stats[i, cv2.CC_STAT_LEFT])
                y = int(stats[i, cv2.CC_STAT_TOP])
                w_ = int(stats[i, cv2.CC_STAT_WIDTH])
                h_ = int(stats[i, cv2.CC_STAT_HEIGHT])
                elong = (max(w_, h_) / max(1.0, min(w_, h_)))
                ys, xs = np.where(labels == i)
                if xs.size > 5:
                    x_mean = xs.mean(); y_mean = ys.mean()
                    x_c = xs - x_mean; y_c = ys - y_mean
                    cov_xx = float(np.mean(x_c*x_c)); cov_yy = float(np.mean(y_c*y_c)); cov_xy = float(np.mean(x_c*y_c))
                    theta = 0.5 * np.arctan2(2*cov_xy, (cov_xx - cov_yy))
                    orient_deg = float(np.degrees(theta)) % 180
                else:
                    orient_deg = float('nan')
                # ä¼°è®¡é•¿åº¦ä¸å¹³å‡å®½åº¦ï¼šç»†é•¿ç›®æ ‡ç”¨éª¨æ¶è¿‘ä¼¼é•¿åº¦ï¼Œå¦åˆ™ç”¨ç­‰æ•ˆç›´å¾„
                comp_mask = (labels == i).astype(np.uint8)
                length_px = float(np.sqrt((w_**2 + h_**2)))
                mean_width_px = float(area / max(1.0, length_px))
                # è‹¥å·²æ ‡å®šï¼Œè½¬æ¢åˆ°æ¯«ç±³
                ppmm = st.session_state.get('ppmm')
                length_mm = (length_px / ppmm) if ppmm else None
                mean_width_mm = (mean_width_px / ppmm) if ppmm else None
                rows.append({
                    'area_px': area,
                    'bbox_w': w_,
                    'bbox_h': h_,
                    'elongation': round(elong,3),
                    'orientation_deg': round(orient_deg,2),
                    'length_px': round(length_px,2),
                    'mean_width_px': round(mean_width_px,2),
                    **({'length_mm': round(length_mm,2), 'mean_width_mm': round(mean_width_mm,2)} if ppmm else {})
                })
            return rows

        import pandas as _pd_alias
        metrics = {
            'è£‚ç¼': extract_components(mask_crack),
            'å‰¥è½': extract_components(mask_peel),
            'è¤ªè‰²': extract_components(mask_disc),
            'æ±¡æ¸/éœ‰æ–‘': extract_components(mask_stain),
            'ç›èš€/é£åŒ–': extract_components(mask_salt),
            'ç”Ÿç‰©é™„ç€': extract_components(mask_bio)
        }
        st.markdown("### ğŸ” ç»†åŒ–ç—…ç†æŒ‡æ ‡ï¼ˆæŒ‰ç±»åˆ«ï¼‰")
        cat_tabs = st.tabs(list(metrics.keys()))
        for tab, (cat, rows) in zip(cat_tabs, metrics.items()):
            with tab:
                if len(rows) == 0:
                    st.write("æ— æ˜¾è‘—è¿é€šåŸŸï¼ˆå—æœ€å°é¢ç§¯é˜ˆå€¼å½±å“ï¼‰")
                else:
                    df = _pd_alias.DataFrame(rows)
                    stats_msg = f"è¿é€šåŸŸæ•°é‡ï¼š{len(df)}ï¼Œé¢ç§¯ä¸­ä½æ•°ï¼š{df['area_px'].median():.0f} pxï¼Œç»†é•¿æ¯”P95ï¼š{df['elongation'].quantile(0.95):.2f}"
                    if 'mean_width_mm' in df.columns:
                        stats_msg += f"ï¼Œå¹³å‡å®½åº¦ä¸­ä½æ•°ï¼š{df['mean_width_mm'].median():.2f} mm"
                    st.write(stats_msg)
                    st.dataframe(df.sort_values('area_px', ascending=False).head(50), use_container_width=True)
                    csv = df.to_csv(index=False).encode('utf-8')
                    st.download_button(label=f"ä¸‹è½½{cat}æŒ‡æ ‡CSV", data=csv, file_name=f"metrics_{cat}.csv", mime="text/csv")

        # textual suggestions
        st.markdown("### ğŸ’¡ å»ºè®®ï¼ˆå¯¹ç—‡æ–¹æ¡ˆï¼‰")
        pct_map = {
            'crack': crack_pct,
            'peel': peel_pct,
            'disc': disc_pct,
            'stain': stain_pct,
            'salt': salt_pct,
            'bio': bio_pct
        }
        detailed_recs = build_recommendations(material, pct_map, severity)
        for r in detailed_recs:
            st.write(f"- {r}")

        # inpainting UI moved to a global section that uses cached masks

        # ---------------------
        # Time-comparison (if previous uploaded)
        # ---------------------
        if uploaded_prev:
            prev_bytes = np.asarray(bytearray(uploaded_prev.read()), dtype=np.uint8)
            prev_img = cv2.imdecode(prev_bytes, cv2.IMREAD_COLOR)
            if prev_img is None:
                st.warning("å†å²å›¾åƒæ— æ³•è¯»å–ï¼Œè¯·ç¡®è®¤æ–‡ä»¶æ ¼å¼ä¸å®Œæ•´æ€§ï¼Œå·²è·³è¿‡å†å²å¯¹æ¯”ã€‚")
            else:
                prev_img_proc, scale_prev = preprocess_image(prev_img.copy())
                prev_gray = cv2.cvtColor(prev_img_proc, cv2.COLOR_BGR2GRAY)
                prev_h, prev_w = prev_gray.shape
                # naive comparison: compare masks area difference (after resizing to match)
                # Resize prev masks to current shape if needed
                if prev_img_proc.shape[:2] != img_proc.shape[:2]:
                    prev_img_proc = cv2.resize(prev_img_proc, (img_proc.shape[1], img_proc.shape[0]))
                    prev_gray = cv2.cvtColor(prev_img_proc, cv2.COLOR_BGR2GRAY)
                # detect previous masks (same pipeline)
                p_boxes_crack, p_mask_crack = detect_cracks(prev_gray)
                p_hsv = cv2.cvtColor(prev_img_proc, cv2.COLOR_BGR2HSV)
                p_boxes_peel, p_mask_peel = detect_peeling(p_hsv)
                p_boxes_disc, p_mask_disc = detect_discoloration(p_hsv)
                # compute area change
                prev_crack_area = int(np.sum(p_mask_crack>0))
                prev_peel_area = int(np.sum(p_mask_peel>0))
                prev_disc_area = int(np.sum(p_mask_disc>0))
                st.markdown("### ğŸ•’ å†å²å¯¹æ¯”ç»“æœ")
                st.write(f"- è£‚ç¼é¢ç§¯å˜åŒ–ï¼š{prev_crack_area} -> {crack_area} ï¼ˆå·®å€¼ {crack_area - prev_crack_area} åƒç´ ï¼‰")
                st.write(f"- å‰¥è½é¢ç§¯å˜åŒ–ï¼š{prev_peel_area} -> {peel_area} ï¼ˆå·®å€¼ {peel_area - prev_peel_area} åƒç´ ï¼‰")
                st.write(f"- è¤ªè‰²é¢ç§¯å˜åŒ–ï¼š{prev_disc_area} -> {disc_area} ï¼ˆå·®å€¼ {disc_area - prev_disc_area} åƒç´ ï¼‰")
                # quick assessment
                if (crack_area - prev_crack_area) > (0.05 * total_pixels):
                    st.error("è£‚ç¼é¢ç§¯æ˜¾è‘—å¢åŠ ï¼Œå»ºè®®å°½å¿«å®åœ°è¯„ä¼°ã€‚")
                elif (peel_area - prev_peel_area) > (0.05 * total_pixels):
                    st.error("å‰¥è½é¢ç§¯æ˜¾è‘—å¢åŠ ï¼Œå¯èƒ½å­˜åœ¨è¿›å±•æ€§ç ´åã€‚")

        # ---------------------
        # Generate PDF with annotated image and results
        # ---------------------
        def generate_pdf_report(annotated_rgb, results, material, suggestions_text):
            """Create PDF and return bytesIO"""
            buf = BytesIO()
            doc = SimpleDocTemplate(buf, pagesize=A4)
            styles = getSampleStyleSheet()
            story = []
            story.append(Paragraph("çŸ³çªŸå¯ºå£ç”»ç—…å®³AIè¯Šæ–­æŠ¥å‘Šï¼ˆå‡çº§ç‰ˆï¼‰", styles['Title']))
            story.append(Spacer(1,6))
            story.append(Paragraph(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", styles['Normal']))
            story.append(Spacer(1,12))

            # insert annotated image (save to tmp buffer)
            img_buf = save_annotated_image_bytes(annotated_rgb)
            # reportlab needs a filename-like object; RLImage accepts BytesIO
            story.append(RLImage(img_buf, width=160*mm, height=(160*annotated_rgb.shape[0]/annotated_rgb.shape[1])*mm))
            story.append(Spacer(1,12))

            story.append(Paragraph("<b>ä¸€ã€é‡åŒ–ç»“æœ</b>", styles['Heading2']))
            for line in results:
                story.append(Paragraph(line, styles['Normal']))
            story.append(Spacer(1,8))

            story.append(Paragraph("<b>äºŒã€ç»¼åˆå»ºè®®</b>", styles['Heading2']))
            for line in suggestions_text:
                story.append(Paragraph(line, styles['Normal']))
            story.append(Spacer(1,12))

            if material != "æœªæŒ‡å®š":
                story.append(Paragraph("<b>ä¸‰ã€æè´¨ä¸“ç”¨å»ºè®®</b>", styles['Heading2']))
                for t in MATERIAL_SUGGESTIONS.get(material, []):
                    story.append(Paragraph(t, styles['Normal']))
                story.append(Spacer(1,8))

            story.append(Paragraph(f"Â© {datetime.now().year} ä¸Šæµ·äº¤å¤§æ–‡ç‰©ä¿®å¤å›¢é˜Ÿ | AI+æ–‡ç‰©ä¿æŠ¤ç ”ç©¶", styles['Normal']))
            doc.build(story)
            buf.seek(0)
            return buf

        results_lines = [
            f"è£‚ç¼è¦†ç›–é¢ç§¯ï¼š{crack_area} åƒç´ ï¼Œå æ¯” {crack_pct:.4f}%",
            f"å‰¥è½è¦†ç›–é¢ç§¯ï¼š{peel_area} åƒç´ ï¼Œå æ¯” {peel_pct:.4f}%",
            f"è¤ªè‰²è¦†ç›–é¢ç§¯ï¼š{disc_area} åƒç´ ï¼Œå æ¯” {disc_pct:.4f}%",
            f"æ±¡æ¸/éœ‰æ–‘è¦†ç›–é¢ç§¯ï¼š{stain_area} åƒç´ ï¼Œå æ¯” {stain_pct:.4f}%",
            f"ç›èš€/é£åŒ–è¦†ç›–é¢ç§¯ï¼š{salt_area} åƒç´ ï¼Œå æ¯” {salt_pct:.4f}%",
            f"ç”Ÿç‰©é™„ç€è¦†ç›–é¢ç§¯ï¼š{bio_area} åƒç´ ï¼Œå æ¯” {bio_pct:.4f}%",
            f"æ•´ä½“ä¸¥é‡åº¦è¯„åˆ†ï¼ˆ0-100ï¼‰ï¼š{severity}ï¼Œç­‰çº§ï¼š{lvl}"
        ]
        suggestions_text = detailed_recs

        pdf_buf = generate_pdf_report(annotated, results_lines, material, suggestions_text)
        st.download_button("â¬‡ï¸ ä¸‹è½½è¯Šæ–­æŠ¥å‘Šï¼ˆå«æ ‡æ³¨å›¾ï¼‰PDF", data=pdf_buf.getvalue(), file_name="è¯Šæ–­æŠ¥å‘Š_å£ç”».pdf", mime="application/pdf")

        # Cache results for interactive toggling without re-uploading
        st.session_state["proc"] = {
            'img_rgb': img_rgb,
            'masks': {
                'crack': mask_crack, 'peel': mask_peel, 'disc': mask_disc,
                'stain': mask_stain, 'salt': mask_salt, 'bio': mask_bio
            },
            'boxes': {
                'crack': boxes_crack, 'peel': boxes_peel, 'disc': boxes_disc,
                'stain': boxes_stain, 'salt': boxes_salt, 'bio': boxes_bio
            },
            'shape': gray.shape
        }

with tabs[1]:
    st.markdown("#### ä¸Šä¼ ä¸¤æœŸä¸‰ç»´æ•°æ®ï¼ˆç‚¹äº‘/ç½‘æ ¼ï¼‰")
    f_epoch1 = st.file_uploader("ä¸Šä¼ ä¸€æœŸï¼ˆå‚è€ƒï¼‰PLY/PCD/OBJ/GLB", type=["ply","pcd","obj","glb"], key="pc1")
    f_epoch2 = st.file_uploader("ä¸Šä¼ äºŒæœŸï¼ˆå¯¹æ¯”ï¼‰PLY/PCD/OBJ/GLB", type=["ply","pcd","obj","glb"], key="pc2")
    max_points = st.number_input("å¯è§†åŒ–/è®¡ç®—æœ€å¤§ç‚¹æ•°ï¼ˆä¸‹é‡‡æ ·ï¼‰", min_value=10000, value=200000, step=10000)
    run_icp = st.button("æ‰§è¡Œé…å‡†ä¸è·ç¦»è®¡ç®—ï¼ˆåŸºç¡€ï¼‰")
    if run_icp:
        if o3d is None:
            st.error("ç¼ºå°‘ open3dï¼Œè¯·å…ˆå®‰è£…ï¼špip install open3d")
        elif f_epoch1 is None or f_epoch2 is None:
            st.error("è¯·ä¸Šä¼ ä¸¤æœŸä¸‰ç»´æ•°æ®æ–‡ä»¶ã€‚")
        else:
            try:
                def load_geom(file):
                    import tempfile
                    suffix = "." + file.name.split(".")[-1].lower()
                    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                        tmp.write(file.read()); path = tmp.name
                    mesh = None
                    if suffix in (".obj", ".glb"):
                        mesh = o3d.io.read_triangle_mesh(path)
                        if not mesh.has_vertices():
                            raise RuntimeError("æ— æ³•è¯»å–ç½‘æ ¼")
                        pcd = mesh.sample_points_uniformly(number_of_points=int(max_points))
                    else:
                        pcd = o3d.io.read_point_cloud(path)
                        if len(pcd.points) == 0:
                            raise RuntimeError("æ— æ³•è¯»å–ç‚¹äº‘")
                    if len(pcd.points) > max_points:
                        pcd = pcd.random_down_sample(float(max_points)/float(len(pcd.points)))
                    pcd.estimate_normals()
                    return pcd

                p1 = load_geom(f_epoch1)
                p2 = load_geom(f_epoch2)
                # ç²—é…å‡†ï¼šåŸºäºè´¨å¿ƒå¯¹é½
                c1 = p1.get_center(); c2 = p2.get_center()
                p2_t = p2.translate(c1 - c2, relative=False)
                # ç²¾é…å‡†ï¼šICP
                with st.spinner("ICPç²¾é…å‡†ä¸­â€¦"):
                    # å…ˆå…¨å±€é…å‡†å°è¯•ï¼ˆRANSACï¼‰å†ICPï¼ˆè‹¥å¯ç”¨ï¼‰
                    try:
                        voxel = max(float(icp_threshold)*2.0, 0.01)
                        p1_down = p1.voxel_down_sample(voxel)
                        p2_down = p2_t.voxel_down_sample(voxel)
                        reg_ransac = o3d.pipelines.registration.registration_ransac_based_on_correspondence(
                            p2_down, p1_down, o3d.utility.Vector2iVector(np.array([[0,0]], dtype=np.int32)),
                            max_correspondence_distance=float(icp_threshold)*3.0,
                            estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(),
                            ransac_n=3,
                            criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(1000, 500)
                        )
                        init = reg_ransac.transformation if hasattr(reg_ransac, 'transformation') else np.eye(4)
                    except Exception:
                        init = np.eye(4)
                    reg = o3d.pipelines.registration.registration_icp(
                        p2_t, p1, float(icp_threshold), init,
                        o3d.pipelines.registration.TransformationEstimationPointToPoint()
                    )
                    p2_aligned = p2_t.transform(reg.transformation)
                    # è®¡ç®—æœ€è¿‘ç‚¹è·ç¦»
                    pcd_tree = o3d.geometry.KDTreeFlann(p1)
                dists = []
                pts = np.asarray(p2_aligned.points)
                for pt in pts:
                    [k, idx, _] = pcd_tree.search_knn_vector_3d(pt, 1)
                    if k > 0:
                        nn = np.asarray(p1.points)[idx[0]]
                        dists.append(float(np.linalg.norm(pt - nn)))
                if len(dists) == 0:
                    st.warning("è·ç¦»è®¡ç®—ä¸ºç©ºã€‚")
                else:
                    dists = np.array(dists)
                    st.write(f"ç‚¹æ•°ï¼š{len(dists)}ï¼Œå‡å€¼ï¼š{dists.mean()*1000:.2f} mmï¼ŒP95ï¼š{np.quantile(dists,0.95)*1000:.2f} mmï¼Œæœ€å¤§ï¼š{dists.max()*1000:.2f} mm")
                    if px is not None:
                        df = pd.DataFrame({"dist_mm": dists*1000.0})
                        st.plotly_chart(px.histogram(df, x="dist_mm", nbins=50, title="è·ç¦»åˆ†å¸ƒ(mm)"), use_container_width=True)
                    # å¯¼å‡ºCSV
                    csv = ("dist_mm\n" + "\n".join(f"{v*1000:.4f}" for v in dists)).encode("utf-8")
                    st.download_button("ä¸‹è½½è·ç¦»åˆ†å¸ƒCSV", data=csv, file_name="distances_mm.csv", mime="text/csv")
            except Exception as e:
                st.exception(e)
                st.error("ä¸‰ç»´å¤„ç†å¤±è´¥ï¼Œè¯·ç¡®è®¤æ–‡ä»¶æ ¼å¼å¹¶é€‚å½“è°ƒå°ç‚¹æ•°æˆ–é˜ˆå€¼ã€‚")

with tabs[2]:
    st.markdown("#### ä¸Šä¼ æ–‡çŒ®/èµ„æ–™å›¾ç‰‡è¿›è¡Œæ–‡å­—è¯†åˆ«ï¼ˆOCRï¼‰")
    if RapidOCR is None:
        st.info("æœªå®‰è£… rapidocr-onnxruntimeï¼Œå¦‚éœ€OCRï¼špip install rapidocr-onnxruntime")
    else:
        files_txt = st.file_uploader("ä¸Šä¼ å›¾ç‰‡ï¼ˆå¯å¤šé€‰ï¼‰JPG/PNG", type=["jpg","jpeg","png"], accept_multiple_files=True, key="ocr_multi")
        run_ocr = st.button("å¼€å§‹è¯†åˆ«", key="run_ocr_batch")
        if run_ocr:
            if not files_txt:
                st.warning("è¯·å…ˆé€‰æ‹©è‡³å°‘ä¸€å¼ å›¾ç‰‡ã€‚")
            else:
                ocr = get_rapidocr_cached()
                if ocr is None:
                    st.error("OCR åˆå§‹åŒ–å¤±è´¥ã€‚")
                else:
                    all_lines = []
                    for idx, f in enumerate(files_txt, start=1):
                        st.write(f"ç¬¬ {idx} ä¸ªæ–‡ä»¶ï¼š{f.name}")
                        img_bytes = np.asarray(bytearray(f.read()), dtype=np.uint8)
                        img = cv2.imdecode(img_bytes, cv2.IMREAD_COLOR)
                        if img is None:
                            st.warning("æ— æ³•è¯»å–è¯¥å›¾ç‰‡ï¼Œå·²è·³è¿‡ã€‚")
                            continue
                        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                        with st.spinner("OCRè¯†åˆ«ä¸­â€¦"):
                            res, elapse = ocr(rgb)
                        lines = []
                        if res:
                            for box, text, score in res:
                                line = f"{text}\t{score:.3f}"
                                lines.append(line)
                                all_lines.append(f"[{f.name}]\t{line}")
                            st.success(f"è¯†åˆ« {len(lines)} è¡Œï¼Œç”¨æ—¶ {elapse:.2f}s")
                            st.code("\n".join(lines))
                        else:
                            st.info("æœªè¯†åˆ«åˆ°æ–‡æœ¬ã€‚")
                    if all_lines:
                        txt = ("\n".join(all_lines)).encode("utf-8")
                        st.download_button("ä¸‹è½½å…¨éƒ¨OCRç»“æœï¼ˆtxtï¼‰", data=txt, file_name="ocr_results.txt", mime="text/plain")

with tabs[3]:
    st.markdown("#### å¤šæ¨¡æ€èåˆè¯Šæ–­ç³»ç»Ÿ")
    st.info("ğŸš€ **å‰æ²¿åŠŸèƒ½**ï¼šç»“åˆå›¾åƒã€3Dç‚¹äº‘ã€æ–‡çŒ®æ–‡æœ¬è¿›è¡Œç»¼åˆè¯Šæ–­ï¼Œæä¾›æ·±åº¦åˆ†æå’Œè™šæ‹Ÿä¿®å¤")
    
    if not MULTIMODAL_AVAILABLE:
        st.warning("âš ï¸ å¤šæ¨¡æ€åŠŸèƒ½éœ€è¦é¢å¤–ä¾èµ–ï¼Œè¯·å®‰è£…ï¼š`pip install torch transformers networkx scikit-learn`")
        st.code("pip install torch transformers networkx scikit-learn")
    else:
        # å¤šæ¨¡æ€æ•°æ®ä¸Šä¼ 
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("##### ğŸ“¸ å›¾åƒæ•°æ®")
            multimodal_image = st.file_uploader("ä¸Šä¼ å£ç”»å›¾åƒ", type=['jpg','jpeg','png'], key="multimodal_img")
            
            st.markdown("##### ğŸ“„ æ–‡çŒ®æ•°æ®")
            multimodal_text = st.text_area("è¾“å…¥ç›¸å…³æ–‡çŒ®è®°å½•ï¼ˆå¦‚å†å²ä¿®å¤è®°å½•ã€æè´¨æè¿°ç­‰ï¼‰", 
                                         placeholder="ä¾‹å¦‚ï¼šè¯¥å£ç”»ä½äºæ•¦ç…Œè«é«˜çªŸç¬¬257çªŸï¼Œç»˜åˆ¶äºåŒ—é­æ—¶æœŸï¼Œä¸»è¦æè´¨ä¸ºç ‚å²©...", 
                                         height=100, key="multimodal_text")
        
        with col2:
            st.markdown("##### ğŸ—ï¸ 3Dç‚¹äº‘æ•°æ®")
            multimodal_pointcloud = st.file_uploader("ä¸Šä¼ 3Dæ‰«ææ•°æ®", type=['ply','pcd','xyz'], key="multimodal_pc")
            
            st.markdown("##### ğŸ›ï¸ çŸ³çªŸä¿¡æ¯")
            cave_type = st.selectbox("é€‰æ‹©çŸ³çªŸç±»å‹", 
                                   ["æ•¦ç…Œè«é«˜çªŸ", "äº‘å†ˆçŸ³çªŸ", "é¾™é—¨çŸ³çªŸ", "éº¦ç§¯å±±çŸ³çªŸ", "å…¶ä»–"], 
                                   key="cave_type")
            
            material_type = st.selectbox("é€‰æ‹©æè´¨ç±»å‹", 
                                       ["ç ‚å²©", "èŠ±å²—å²©", "çŸ³ç°å²©", "æ³¥è´¨ç ‚å²©", "å…¶ä»–"], 
                                       key="material_type")
        
        # å¤šæ¨¡æ€åˆ†ææŒ‰é’®
        run_multimodal = st.button("ğŸ” å¼€å§‹å¤šæ¨¡æ€èåˆåˆ†æ", key="run_multimodal")
        
        if run_multimodal:
            if not multimodal_image:
                st.warning("è¯·è‡³å°‘ä¸Šä¼ ä¸€å¼ å›¾åƒè¿›è¡Œåˆ†æ")
            else:
                # åˆå§‹åŒ–å¤šæ¨¡æ€ç³»ç»Ÿ
                multimodal_system = get_multimodal_system()
                auto_annotator = get_auto_annotator()
                generative_aug = get_generative_augmentation()
                
                # å¤„ç†å›¾åƒ
                img_bytes = multimodal_image.read()
                img_array = np.frombuffer(img_bytes, dtype=np.uint8)
                image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
                
                # å¤„ç†ç‚¹äº‘
                pointcloud = None
                if multimodal_pointcloud:
                    try:
                        pc_bytes = multimodal_pointcloud.read()
                        if multimodal_pointcloud.name.endswith('.ply'):
                            pointcloud = o3d.io.read_point_cloud_from_bytes(pc_bytes, format='ply')
                        elif multimodal_pointcloud.name.endswith('.pcd'):
                            pointcloud = o3d.io.read_point_cloud_from_bytes(pc_bytes, format='pcd')
                    except Exception as e:
                        st.warning(f"ç‚¹äº‘åŠ è½½å¤±è´¥ï¼š{e}")
                
                # å¤šæ¨¡æ€ç‰¹å¾æå–
                with st.spinner("ğŸ”„ å¤šæ¨¡æ€ç‰¹å¾æå–ä¸­..."):
                    # å›¾åƒç‰¹å¾
                    image_features = multimodal_system.encode_image(image)
                    
                    # ç‚¹äº‘ç‰¹å¾
                    pointcloud_features = multimodal_system.encode_pointcloud(pointcloud)
                    
                    # æ–‡æœ¬ç‰¹å¾
                    text_features = multimodal_system.encode_text(multimodal_text)
                    
                    # ç‰¹å¾èåˆ
                    fused_features = multimodal_system.fuse_modalities(image_features, pointcloud_features, text_features)
                
                # æ˜¾ç¤ºç‰¹å¾ä¿¡æ¯
                st.success("âœ… å¤šæ¨¡æ€ç‰¹å¾æå–å®Œæˆ")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("å›¾åƒç‰¹å¾ç»´åº¦", f"{len(image_features) if image_features is not None else 0}")
                with col2:
                    st.metric("ç‚¹äº‘ç‰¹å¾ç»´åº¦", f"{len(pointcloud_features) if pointcloud_features is not None else 0}")
                with col3:
                    st.metric("æ–‡æœ¬ç‰¹å¾ç»´åº¦", f"{len(text_features) if text_features is not None else 0}")
                
                # æ·±åº¦ç¨³å®šæ€§åˆ†æ
                if pointcloud is not None:
                    st.markdown("##### ğŸ” æ·±åº¦ç¨³å®šæ€§åˆ†æ")
                    
                    # å…ˆè¿›è¡Œç—…å®³æ£€æµ‹è·å–è£‚ç¼æ©ç 
                    with st.spinner("ğŸ”„ è¿›è¡Œç—…å®³æ£€æµ‹..."):
                        # ä½¿ç”¨ç°æœ‰çš„ç—…å®³æ£€æµ‹åŠŸèƒ½
                        crack_mask = detect_crack(image) if 'detect_crack' in globals() else None
                        if crack_mask is not None:
                            depth_analysis = multimodal_system.analyze_depth_stability(image, pointcloud, crack_mask)
                            
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("è£‚ç¼æ·±åº¦", depth_analysis["depth"])
                            with col2:
                                st.metric("ç»“æ„ç¨³å®šæ€§", depth_analysis["stability"])
                            with col3:
                                st.metric("åˆ†æç½®ä¿¡åº¦", f"{depth_analysis['confidence']:.2f}")
                            
                            if "depth_variance" in depth_analysis:
                                st.info(f"æ·±åº¦æ–¹å·®ï¼š{depth_analysis['depth_variance']:.4f}")
                            if "point_density" in depth_analysis:
                                st.info(f"ç‚¹äº‘å¯†åº¦ï¼š{depth_analysis['point_density']:.2f}")
                        else:
                            st.warning("æœªæ£€æµ‹åˆ°è£‚ç¼ï¼Œæ— æ³•è¿›è¡Œæ·±åº¦åˆ†æ")
                
                # çŸ¥è¯†å›¾è°±æŸ¥è¯¢
                st.markdown("##### ğŸ§  çŸ¥è¯†å›¾è°±æ™ºèƒ½è¯Šæ–­")
                
                # æ¨¡æ‹Ÿæ£€æµ‹åˆ°çš„ç—…å®³
                detected_pathologies = ["è¡¨é¢è£‚ç¼", "å‰¥è½"]  # è¿™é‡Œåº”è¯¥åŸºäºå®é™…æ£€æµ‹ç»“æœ
                
                treatments = multimodal_system.knowledge_graph.query_treatment(
                    cave_type, material_type, detected_pathologies
                )
                
                if treatments:
                    st.success("ğŸ¯ åŸºäºçŸ¥è¯†å›¾è°±çš„ä¿®å¤å»ºè®®ï¼š")
                    for i, treatment in enumerate(treatments[:3]):  # æ˜¾ç¤ºå‰3ä¸ªå»ºè®®
                        with st.expander(f"å»ºè®® {i+1}: {treatment['treatment']}"):
                            st.write(f"**é€‚ç”¨ç—…å®³**: {treatment['pathology']}")
                            st.write(f"**é€‚ç”¨æ€§**: {treatment['suitability']:.2f}")
                            st.write(f"**æˆæœ¬**: {treatment['cost']}")
                            st.write(f"**æ•ˆæœ**: {treatment['effectiveness']}")
                            st.write(f"**æŒä¹…æ€§**: {treatment['durability']}")
                else:
                    st.info("æœªæ‰¾åˆ°åŒ¹é…çš„ä¿®å¤å»ºè®®")
                
                # è‡ªåŠ¨æ ‡æ³¨
                st.markdown("##### ğŸ·ï¸ æ™ºèƒ½è‡ªåŠ¨æ ‡æ³¨")
                
                # æ¨¡æ‹Ÿæ£€æµ‹åŒºåŸŸ
                mock_regions = [
                    {"area": 500, "bbox": [100, 100, 50, 30], "elongation": 0.8},
                    {"area": 1200, "bbox": [200, 150, 80, 40], "elongation": 0.6}
                ]
                
                annotations = auto_annotator.generate_annotation(image, mock_regions, "crack")
                
                if annotations:
                    st.success("ğŸ“ è‡ªåŠ¨æ ‡æ³¨ç»“æœï¼š")
                    for i, annotation in enumerate(annotations):
                        with st.expander(f"æ ‡æ³¨ {i+1}: {annotation['type']} - {annotation['severity']}"):
                            st.write(f"**æè¿°**: {annotation['description']}")
                            st.write(f"**é¢ç§¯**: {annotation['area']} åƒç´ ")
                            st.write(f"**ç½®ä¿¡åº¦**: {annotation['confidence']:.2f}")
                            st.write(f"**ç‰¹å¾**: é•¿å®½æ¯” {annotation['features']['aspect_ratio']:.2f}")
                
                # è™šæ‹Ÿä¿®å¤
                st.markdown("##### ğŸ¨ è™šæ‹Ÿä¿®å¤é¢„è§ˆ")
                
                if crack_mask is not None:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**åŸå§‹å›¾åƒ**")
                        st.image(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), use_column_width=True)
                    
                    with col2:
                        st.write("**è™šæ‹Ÿä¿®å¤å**")
                        restored = generative_aug.virtual_restoration(image, crack_mask, "crack")
                        st.image(cv2.cvtColor(restored, cv2.COLOR_BGR2RGB), use_column_width=True)
                    
                    # ä¿®å¤æ•ˆæœå¯¹æ¯”
                    st.markdown("##### ğŸ“Š ä¿®å¤æ•ˆæœåˆ†æ")
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("ä¿®å¤ç®—æ³•", "Telea Inpainting")
                    with col2:
                        st.metric("ä¿®å¤åŒºåŸŸ", f"{np.sum(crack_mask > 0)} åƒç´ ")
                    with col3:
                        st.metric("ä¿®å¤è´¨é‡", "é«˜")
                
                # ç»¼åˆæŠ¥å‘Š
                st.markdown("##### ğŸ“‹ å¤šæ¨¡æ€è¯Šæ–­æŠ¥å‘Š")
                
                report_data = {
                    "çŸ³çªŸç±»å‹": cave_type,
                    "æè´¨ç±»å‹": material_type,
                    "å›¾åƒè´¨é‡": "è‰¯å¥½" if image_features is not None else "æœªçŸ¥",
                    "3Dæ•°æ®": "å¯ç”¨" if pointcloud_features is not None else "ä¸å¯ç”¨",
                    "æ–‡çŒ®æ•°æ®": "å·²æä¾›" if text_features is not None else "æœªæä¾›",
                    "èåˆç‰¹å¾ç»´åº¦": len(fused_features) if fused_features is not None else 0,
                    "æ£€æµ‹ç—…å®³æ•°": len(detected_pathologies),
                    "ä¿®å¤å»ºè®®æ•°": len(treatments)
                }
                
                report_df = pd.DataFrame(list(report_data.items()), columns=["é¡¹ç›®", "ç»“æœ"])
                st.dataframe(report_df, use_container_width=True)
                
                # ä¸‹è½½æŠ¥å‘Š
                report_text = f"""
å¤šæ¨¡æ€èåˆè¯Šæ–­æŠ¥å‘Š
==================

åŸºæœ¬ä¿¡æ¯ï¼š
- çŸ³çªŸç±»å‹ï¼š{cave_type}
- æè´¨ç±»å‹ï¼š{material_type}
- åˆ†ææ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ•°æ®è´¨é‡ï¼š
- å›¾åƒæ•°æ®ï¼š{'å¯ç”¨' if image_features is not None else 'ä¸å¯ç”¨'}
- 3Dç‚¹äº‘ï¼š{'å¯ç”¨' if pointcloud_features is not None else 'ä¸å¯ç”¨'}
- æ–‡çŒ®æ–‡æœ¬ï¼š{'å·²æä¾›' if text_features is not None else 'æœªæä¾›'}

æ£€æµ‹ç»“æœï¼š
- æ£€æµ‹åˆ°ç—…å®³ï¼š{', '.join(detected_pathologies)}
- ä¿®å¤å»ºè®®ï¼š{len(treatments)} æ¡

æŠ€æœ¯æŒ‡æ ‡ï¼š
- èåˆç‰¹å¾ç»´åº¦ï¼š{len(fused_features) if fused_features is not None else 0}
- åˆ†æç½®ä¿¡åº¦ï¼š{depth_analysis.get('confidence', 0):.2f}ï¼ˆå¦‚æœ‰3Dæ•°æ®ï¼‰
                """
                
                st.download_button(
                    "ğŸ“¥ ä¸‹è½½å¤šæ¨¡æ€è¯Šæ–­æŠ¥å‘Š",
                    data=report_text.encode('utf-8'),
                    file_name=f"multimodal_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain"
                )

# footer
st.markdown(f"<div style='text-align:center;color:#666;margin-top:32px;'>Â© {datetime.now().year} ä¸Šæµ·äº¤å¤§æ–‡ç‰©ä¿®å¤å›¢é˜Ÿ | AI+æ–‡ç‰©ä¿æŠ¤ç ”ç©¶</div>", unsafe_allow_html=True)

# If cached results exist, allow re-render with current toggles without re-uploading
if st.session_state.get("proc") is not None and (uploaded is None or not analyze_btn):
    cache = st.session_state["proc"]
    img_rgb = cache['img_rgb']
    masks = cache['masks']
    boxes_map = cache['boxes']
    h, w = cache['shape']

    mask_crack = masks['crack']; mask_peel = masks['peel']; mask_disc = masks['disc']
    mask_stain = masks['stain']; mask_salt = masks['salt']; mask_bio = masks['bio']
    boxes_crack = boxes_map['crack']; boxes_peel = boxes_map['peel']; boxes_disc = boxes_map['disc']
    boxes_stain = boxes_map['stain']; boxes_salt = boxes_map['salt']; boxes_bio = boxes_map['bio']

    annotated = img_rgb.copy()
    def draw_boxes(boxes, color, visible, tag_text):
        if not visible or display_mode == "ä»…æ©è†œ":
            return
        for (x,y,w_,h_) in boxes:
            if w_*h_ < min_area:
                continue
            cv2.rectangle(annotated, (x,y), (x+w_, y+h_), color, 2)
            if show_labels:
                tx = x; ty = max(0, y-8)
                text = tag_text
                (tw, th), bl = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.45, 1)
                cv2.rectangle(annotated, (tx, ty-th-4), (tx+tw+4, ty+2), (0,0,0), -1)
                cv2.putText(annotated, text, (tx+2, ty-2), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 1, cv2.LINE_AA)

    if label_lang == "ä¸­æ–‡":
        crack_t, peel_t, disc_t, stain_t, salt_t, bio_t = "è£‚", "å‰¥", "è¤ª", "æ±¡", "ç›", "ç”Ÿ"
    else:
        crack_t, peel_t, disc_t, stain_t, salt_t, bio_t = "CR", "PL", "DC", "ST", "SA", "BIO"

    draw_boxes(boxes_crack, (255,0,0), show_crack, crack_t)
    draw_boxes(boxes_peel, (0,255,0), show_peel, peel_t)
    draw_boxes(boxes_disc, (0,0,255), show_disc, disc_t)
    draw_boxes(boxes_stain, (255,255,0), show_stain, stain_t)
    draw_boxes(boxes_salt, (0,255,255), show_salt, salt_t)
    draw_boxes(boxes_bio, (255,0,255), show_bio, bio_t)

    def overlay_mask(base_rgb, mask, color_rgb, alpha=0.35):
        overlay = base_rgb.copy()
        mask_bool = mask > 0
        overlay[mask_bool] = (overlay[mask_bool] * (1-alpha) + np.array(color_rgb) * alpha).astype(np.uint8)
        return overlay

    if display_mode in ("ä»…æ©è†œ", "è¾¹æ¡†+æ©è†œ"):
        if show_crack:
            annotated = overlay_mask(annotated, mask_crack, (255,0,0), alpha=0.25)
        if show_peel:
            annotated = overlay_mask(annotated, mask_peel, (0,255,0), alpha=0.18)
        if show_disc:
            annotated = overlay_mask(annotated, mask_disc, (0,0,255), alpha=0.18)
        if show_stain:
            annotated = overlay_mask(annotated, mask_stain, (255,255,0), alpha=0.20)
        if show_salt:
            annotated = overlay_mask(annotated, mask_salt, (0,255,255), alpha=0.18)
        if show_bio:
            annotated = overlay_mask(annotated, mask_bio, (255,0,255), alpha=0.20)

    st.subheader("åˆ†æç»“æœï¼ˆå¸¦æ ‡æ³¨ï¼‰")
    st.image(annotated, width='stretch')

    legend_html = """
    <div style='display:flex;flex-wrap:wrap;gap:12px;margin:6px 0 10px 0;'>
      <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#ff0000;'></span><span>è£‚ç¼</span></div>
      <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#00cc00;'></span><span>å‰¥è½</span></div>
      <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#0000ff;'></span><span>è¤ªè‰²</span></div>
      <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#ffff00;'></span><span>æ±¡æ¸/éœ‰æ–‘</span></div>
      <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#00ffff;'></span><span>ç›èš€/é£åŒ–</span></div>
      <div style='display:flex;align-items:center;gap:6px;'><span style='display:inline-block;width:14px;height:14px;background:#ff00ff;'></span><span>ç”Ÿç‰©é™„ç€</span></div>
    </div>
    """
    st.markdown(legend_html, unsafe_allow_html=True)
    # è‰²å½©å¤åŸï¼ˆç¼“å­˜å›¾ï¼‰
    render_color_restore_ui(img_rgb, default_open=False, key_suffix="color_cached")

    total_pixels = h*w
    crack_area = int(np.sum(mask_crack>0)); peel_area = int(np.sum(mask_peel>0)); disc_area = int(np.sum(mask_disc>0))
    stain_area = int(np.sum(mask_stain>0)); salt_area = int(np.sum(mask_salt>0)); bio_area = int(np.sum(mask_bio>0))

    crack_pct = crack_area / total_pixels * 100
    peel_pct = peel_area / total_pixels * 100
    disc_pct = disc_area / total_pixels * 100
    stain_pct = stain_area / total_pixels * 100
    salt_pct = salt_area / total_pixels * 100
    bio_pct = bio_area / total_pixels * 100

    weights = MATERIAL_WEIGHTS.get(material, MATERIAL_WEIGHTS["æœªæŒ‡å®š"])
    score = (
        weights.get('crack',1.0) * crack_pct * 1.8 +
        weights.get('peel',1.0) * peel_pct * 1.2 +
        weights.get('disc',1.0) * disc_pct * 1.5 +
        weights.get('stain',1.0) * stain_pct * 0.9 +
        weights.get('salt',1.0) * salt_pct * 1.6 +
        weights.get('bio',1.0) * bio_pct * 1.1
    )
    severity = min(round(score,1), 100.0)
    if severity < 5:
        lvl = "è½»å¾®"
    elif severity < 20:
        lvl = "ä¸­ç­‰"
    else:
        lvl = "ä¸¥é‡"

    st.markdown("### ğŸ“‹ é‡åŒ–ç»“æœ")
    st.write(f"- è£‚ç¼è¦†ç›–é¢ç§¯ï¼š{crack_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {crack_pct:.3f}%")
    st.write(f"- å‰¥è½è¦†ç›–é¢ç§¯ï¼š{peel_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {peel_pct:.3f}%")
    st.write(f"- è¤ªè‰²è¦†ç›–é¢ç§¯ï¼š{disc_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {disc_pct:.3f}%")
    st.write(f"- æ±¡æ¸/éœ‰æ–‘è¦†ç›–é¢ç§¯ï¼š{stain_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {stain_pct:.3f}%")
    st.write(f"- ç›èš€/é£åŒ–è¦†ç›–é¢ç§¯ï¼š{salt_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {salt_pct:.3f}%")
    st.write(f"- ç”Ÿç‰©é™„ç€è¦†ç›–é¢ç§¯ï¼š{bio_area} åƒç´ ï¼Œçº¦å å›¾åƒé¢ç§¯ {bio_pct:.3f}%")
    st.write(f"- æè´¨ï¼š**{material}**ï¼ˆç”¨äºè°ƒæ•´è¯„åˆ†ä¸å»ºè®®ï¼‰")
    st.metric("æ•´ä½“ç—…å®³ä¸¥é‡åº¦ï¼ˆ0-100ï¼‰", f"{severity}")

    st.markdown("### ğŸ’¡ å»ºè®®ï¼ˆå¯¹ç—‡æ–¹æ¡ˆï¼‰")
    pct_map = {'crack': crack_pct,'peel': peel_pct,'disc': disc_pct,'stain': stain_pct,'salt': salt_pct,'bio': bio_pct}
    detailed_recs = build_recommendations(material, pct_map, severity)
    for r in detailed_recs:
        st.write(f"- {r}")

    # ---------------------
    # Global inpainting (works with cached results)
    # ---------------------
    render_inpainting_ui(img_rgb, mask_crack, mask_peel, mask_disc, mask_stain, mask_salt, mask_bio, default_open=True, key_suffix="cached")