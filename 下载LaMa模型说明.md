# LaMa AI修复模型下载说明

## 方法1：使用Python脚本自动下载（推荐）

### 步骤：

1. **安装必要的库**（如果还没有安装）：
   ```bash
   pip install requests
   pip install tqdm  # 可选，用于显示进度条
   ```

2. **运行下载脚本**：
   ```bash
   python download_lama_model.py
   ```

3. **等待下载完成**：
   - 脚本会自动下载模型文件到当前目录
   - 文件名为：`lama-fcn_resolution_robust_512.onnx`
   - 文件大小约 50MB

### 注意事项：

- 如果Hugging Face需要登录，脚本可能会失败
- 如果自动下载失败，请使用方法2手动下载

---

## 方法2：手动下载（如果脚本失败）

### 步骤：

1. **访问Hugging Face模型页面**：
   - 打开浏览器，访问：https://huggingface.co/shzym/lama-fcn/tree/main

2. **登录Hugging Face**（如果需要）：
   - 如果没有账号，需要先注册一个免费账号
   - 登录后即可下载

3. **下载模型文件**：
   - 在文件列表中找到：`lama-fcn_resolution_robust_512.onnx`
   - 点击文件名或下载按钮
   - 将文件保存到项目目录（与 `app.py` 同一文件夹）

4. **验证文件**：
   - 确保文件名是：`lama-fcn_resolution_robust_512.onnx`
   - 文件大小应该约 50MB

---

## 方法3：不下载模型（使用传统修复方法）

**即使不下载模型，应用也能正常工作！**

- 代码已经实现了自动降级机制
- 如果模型文件不存在，会自动使用多尺度融合修复方法
- 效果虽然不如AI模型，但比简单的cv2.inpaint要好很多

---

## 验证模型是否加载成功

1. 启动应用：
   ```bash
   streamlit run app.py
   ```

2. 上传图像并进行分析

3. 在"高级图像复原系统"中选择"深度学习修复(模拟)"

4. 查看提示信息：
   - **如果模型已加载**：会显示"正在使用 LaMa (AI) 模型进行修复..."
   - **如果模型未找到**：会显示"LaMa AI模型未找到或加载失败！使用传统多尺度修复方法。"

---

## 常见问题

### Q: 下载失败怎么办？
A: 请尝试手动下载（方法2），或者继续使用传统修复方法（方法3）

### Q: 模型文件放在哪里？
A: 放在与 `app.py` 相同的目录下

### Q: 可以修改模型路径吗？
A: 可以，在 `app.py` 第1663行修改 `LAMA_MODEL_PATH` 变量

### Q: 不下载模型会影响功能吗？
A: 不会，应用会自动使用传统修复方法，功能完全正常

---

## 技术支持

如果遇到问题，请检查：
1. 网络连接是否正常
2. 是否有足够的磁盘空间（至少100MB）
3. Python环境是否正确
4. 是否安装了必要的库（requests）

